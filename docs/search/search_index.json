{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"4DGeo","text":"<p>4DGeo is an open-source, modular, super lightweight, web-based interactive dashboard application for visualizing your geodata time series captured with a continuous and even ongoing 3D environmental monitoring station (e.g. LiDAR, 3D photogrammetry, smartphone). </p>"},{"location":"index.html#about","title":"About","text":"<p>4DGeo enables users to create and share their own dashboard layout to visualise their custom 4D geodata using various available visualization and user-input modules. The project is designed to be flexible and extendable, making it easy to adapt for different use cases such as landslide detection, insect monitoring, and other environmental observations. It can be hosted on a simple server or with Github Pages. The structured input data is read from a user-defined web  source and is updated automatically at regular intervals, as specified in the refresh timer. This enables the 4DGeo dashboard to work particularly well with continuously updated data, such as that from monitoring systems that repeatedly scan an area of interest in addition to static or archive data that does not need constant refreshing.</p>"},{"location":"index.html#get-started-in-2-minutes-visualise-your-point-clouds","title":"Get started in 2 minutes: Visualise your point clouds","text":"<p>To show how easy it is to visualise your data with a 4DGeo dashboard, we've prepared a short Python Notebook tutorial. It demonstrates how a series of point clouds can be projected into images and displayed within the dashboard.</p> <p>The process involves just two simple steps:</p> <ul> <li>Prepare your data: Convert your list of images into the 4DGeo data model. This is what's done in the above mentioned Python Notebook.</li> <li>Configure your dashboard: Either load a predefined layout or create your own with our dashboard creation page</li> </ul> <p>To run this Notebook yourself, just open a command line in your target directory and follow the conda environment installation steps</p>"},{"location":"index.html#key-features","title":"Key Features","text":"<ul> <li>Controlled visualization of your results, for example from various 3D and 4D change analysis methods</li> <li>Time-series support</li> <li>Customizable and shareable dashboards</li> <li>React-based modular UI</li> <li>Automatic data refreshs</li> <li>Easy integration with your data using a self-designed data model</li> </ul>"},{"location":"index.html#development-installation","title":"Development &amp; Installation","text":"<p>To run 4DGeo locally, follow these steps:</p> <ol> <li> <p>Clone the repository:</p> <pre><code>    git clone https://github.com/3dgeo-heidelberg/4DGeo.git\n    cd 4DGeo\n</code></pre> </li> <li> <p>Install dependencies (Check if Node.js is installed on your computer. If not, download it from this link):</p> <pre><code>    npm install\n</code></pre> </li> <li> <p>Start the development server:</p> <pre><code>    npm start\n</code></pre> </li> <li> <p>Open your browser and navigate to:</p> <pre><code>    http://localhost:3000/4DGeo\n</code></pre> </li> </ol>"},{"location":"index.html#hosting-options","title":"Hosting Options","text":"<p>To host this application on your own, there are 2 main options:</p> <ol> <li> <p>We recommend to fork this repository and copy our Github Action workflow for deploying it to Github Pages which is favorable in a production or testing environment and very easy to set up. For that you need to consider the points raised in the fork section below. </p> </li> <li> <p>For a quick and simple locally hosted server, you can also use a static web server setup with, for example, the built-in Python library <code>http.server</code> and used in our examples notebooks like here.</p> </li> </ol>"},{"location":"index.html#forking","title":"Forking","text":"<p>If you want to fork this repository in order to work on it independently, it is necessary to make some adjustments to the settings and content. To assist you in navigating this process, please find below a list of key changes to consider.   </p> <p>For the application to run:</p> <ul> <li>Update the config.json file to reflect your repository's name (e.g., replacing \"4DGeo\" with your preferred name). This file includes information like the path to the app icon, the app name and also the list of template, which should all be modified accordingly.</li> <li>Adjust the \"name\" field in the package.json file.</li> <li>If you also want the documentation to run on your fork, adjust <code>site_name</code>, <code>repo_url</code>, <code>site_url</code> and the <code>4DGeo (Web)</code> navigation link in the mkdocs.yml file.</li> </ul> <p>If you want to also deploy the application to your Github Pages:</p> <ul> <li>Adjust the \"homepage\" field in the package.json file. The \"homepage\" is needed for the Github Pages deployment to work properly. For a better understanding of this workflow, we recommend this article.</li> <li>The Github Action for deploying the Github Pages doesn't need any further adaptations. But if you have trouble starting the workflow or its not showing up in the \"Actions\" tab, create a new workflow in your repository and copy the content. This way the workflow will be Github will definetly recognize it as a new working workflow.</li> </ul>"},{"location":"index.html#documentation","title":"Documentation","text":"<p>As a starting point, the main features of this software are described in the 4DGeo manual. Additionally, to understand how you can use this app and incorporate it into your own Project, you can have a look at the Example Notebooks. The current usages and implementations are described in detail there:</p> <ul> <li>Getting started</li> <li>Beehive monitoring</li> <li>Rockfall monitoring</li> <li>Branch evolution</li> </ul>"},{"location":"index.html#conda-environment-installation","title":"Conda environment installation","text":"<p>For these notebooks to fully work, you need to create a conda environment with the correct dependencies installed.</p> <ol> <li>Clone the GitHub repository in a local folder     <pre><code>git clone https://github.com/3dgeo-heidelberg/4DGeo.git\n</code></pre></li> <li>create the Conda environment with the provided .yml file     <pre><code>cd 4DGeo/docs\nconda env create -n 4DGeo --file 4DGeo_doc.yml\n</code></pre></li> <li>Activate the environment     <pre><code>conda activate 4DGeo\n</code></pre></li> </ol>"},{"location":"index.html#contact-bugs-feature-requests","title":"Contact / Bugs / Feature Requests","text":"<p>Have you found a bug or have specific request for a new feature? Please open a new issue in the online code repository on Github. Also for general questions please use the issue system.</p> <p>Scientific requests can be directed to the 3DGeo Research Group Heidelberg and its respective members.</p>"},{"location":"Application.html","title":"4DGeo Manual","text":"<p>For better understanding and easier usage of the 4DGeo Dashboard, its functionalities, structure, and concepts will be explained here. The Application is split into two parts: firstly, the dashboard creation page, where you can create and configure your own dashboard or load predefined examples and adjust their structure to your needs. And secondly, the dashboard view page which contains the actual dashboard with all the specified visualization modules combined with your data.</p> <p>The following video demonstrates the basic functionality of the app.</p>"},{"location":"Application.html#1-creation-page","title":"1 Creation Page","text":"<p>On the dashboard creation page, you can design your own dashboard with a custom layout including all the modules you want to add, the data source (URL), refresh interval, and color assignment.</p> <p></p>"},{"location":"Application.html#11-data-source","title":"1.1 Data Source","text":"<p>The data source is an integral part of the design of a dashboard. It defines the location of the structured input data that should be read. This has to be a concrete link or URL to a specific file in the correct format.</p>"},{"location":"Application.html#12-refresh-interval","title":"1.2 Refresh Interval","text":"<p>You have the option to specify the frequency of refreshes for the dashboard. At every refresh, the data from your given data source is read and checked for updates. For example, if you have a new analysed scan that you want to include into the dashboard, you just have to update the file in your data source and the dashboard will automatically show this new content on the next refresh. The refresh rate should be set according to the data update rate.</p>"},{"location":"Application.html#13-color-assignment","title":"1.3 Color Assignment","text":"<p>The Color Assignment feature helps create a more appealing and customized visualisation. It works as a map between all the possible types of geoobjects in your data and their respective assigned color, that you can freely choose once loaded. This feature only works when you already specified your data source link because it first reads a snapshot of the data and filters every present type to create the user input. </p> <p>If you dont use this option when creating a dashboard, a random color assignment will be used.</p> <p></p>"},{"location":"Application.html#14-layout","title":"1.4 Layout","text":"<p>The layout of a dashboard is defined as a map of each instance of a module and their position and size in the dashboard. This map approach makes it possible to save this layout information for example as a simple json string.</p>"},{"location":"Application.html#15-permalinks","title":"1.5 Permalinks","text":"<p>Once you have designed your dashboard and configured all the wanted options, you want to see the dashboard in action. But for that, all of your configurations have to be communicated to the dashboard page. For this, all of your input can be saved as a permalink.</p> <p>A permalink hashes all the values into a base64-String. This string is appended as a variable to the URL of the dashboard page. With this approach, each dashboard design can be stored in a simple link and shared and is easily reproducable this way.</p> <p>With the Read from permalink button, you can also read all the configurations of a design inside of the creation page and adjust it to your needs before going to the dashboard page. By this, you can share your perfect layout with others.</p>"},{"location":"Application.html#16-templates","title":"1.6 Templates","text":"<p>The idea of populating the creation section with data from a permalink is expanded with a list of templates. A template is a predefined and fully equipped (example-)dashboard that is connected with sample data from us. Each template is defined in the <code>public/config.json</code> file as a permalink with every design option predefined.</p>"},{"location":"Application.html#2-dashboard-view-page","title":"2 Dashboard View Page","text":"<p>This page is the main visualisation page. A dashboard is generated via the stored information in the permalink with its layout, data source, refresh rate, and color assignment. It is then populated with data automatically read from the given data source. Each module of the dashboard has its own functionality and will be further explained. Based on your specified refresh interval, the dashboard re-reads the data from your data source and updates the content if anything changed.</p> <p></p> <p>The dashboard is built around our self-designed data model.</p> <p></p>"},{"location":"Application.html#21-data-model","title":"2.1 Data Model","text":"<p>Our data model mainly serves the purpose to make the dashboard use-case independent. This way, the app can be used in a variety of 4D monitoring scenarios. You just need to convert your own data  into the 4DGeo data model. This can usually be done very easily by writing a script for automatic data conversion (from yours to 4DGeo) only once. </p> <p></p> <p>It is designed around observations. An observation can be described as a snapshot of the real world over a specified area at a specific short interval in time.  For example, a use-case could be to monitor rockfalls and landslides on a mountain slope with a LiDAR scanner. In this example, an observation would be a single scan of the area.</p> <p>Each observation includes a start- and end-datetime (in ISO 8601 format) for specifying the exact point in time. Additionally, it contains information for a 2D background image to represent the environment at the time of the scan. This information consists of the URL to the image file as well as its width and height in pixels. With each observation having their own respective background image, changes in the environment can be visualized.</p> <p>Lastly, each observation incorporates their own list of geoobjects. A geoobject is a detected and analysed object at a certain location. In our rockfall monitoring example, a detected geoobject could be a single rockfall, represented as a polygon, and its area.</p> <p>A geoobject includes the following attributes:</p> <ul> <li><code>id</code> (String): Your own managed id.</li> <li><code>type</code> (String): The type of geoobject. This is very use-case dependent and can be set as you want.</li> <li><code>datetime</code> (String ISO 8601 format): This specifies the specific point in time inside of the interval of its observation. It has to be a string in ISO 8601 format.</li> <li><code>geometry</code>: In order to visualise a geoobject, they need to specify their geometry. This is comparable to the geometry object in the GeoJSON definition<ul> <li><code>type</code> (String): The type of geometry. Inspired by the GeoJSON geometry type. As of now, Polygons, Points and LineStrings are supported.</li> <li><code>coordinates</code> (Array): The coordinates of a geoobject. The structure of the values are based on the defined geometry type. These coordinates serve to correctly locate the position of the geoobjects in the 2D Viewer Module. The geoobjects will be visualised in front of the background image. The coordinates thus have to be in pixel values with [0, 0] being in the top-left hand corner and [-imageHeight, imageWidth] being in the bottom-right hand corner.</li> </ul> </li> <li><code>customAttributes</code> (Dictionary key-value): These custom attributes cover your use-case dependent information. They represent additional information bound to a specific geoobject. These attributes are the basis for the Chart Module. In our rockfall example, the custom attributes could include data like the rockfall magnitude or total volume.</li> </ul> <p>This is a skeleton overview of how the finished data should look like: <pre><code>{\n    \"observations\": [\n        {\n            \"startDateTime\": \"String in ISO 8601 format\",\n            \"endDateTime\": \"String in ISO 8601 format\",\n            \"backgroundImageData\": {\n                \"url\": \"\",\n                \"height\": 0,\n                \"width\": 0\n            },\n            \"geoObjects\": [\n                {\n                    \"id\": \"\",\n                    \"type\": \"\",\n                    \"dateTime\": \"String in ISO 8601 format\",\n                    \"geometry\": {\n                        \"type\": \"GeoJSON geometry type\",\n                        \"coordinates\": [\n                            [1, 1, 1],\n                            [1, 2, 1]\n                        ]\n                    },\n                    \"customAttributes\": {\n                        \"customKey\": \"\",\n                        \"customKey2\": \"\"\n                    }\n                }\n            ]\n        },\n        {\n            ...\n        }\n    ]\n}\n</code></pre></p> <p></p>"},{"location":"Application.html#3-modules","title":"3 Modules","text":""},{"location":"Application.html#31-visualisation-modules","title":"3.1 Visualisation Modules","text":"<p>With these modules, your data will be visualised in different ways so that you can analyse your data designed for your needs.</p>"},{"location":"Application.html#2d-view-map","title":"2D View Map","text":"<p>In the 2D View, all the geoobjects inside of your data will be rendered with a leaflet map in front of the specified background image. When multiple observations are selected, the background image is taken from the first timestamp. For now, only Polygons, Points, and LineStrings are supported. Each geoobject is assigned a specific color based on their type which you can adjust easily  There are 2 layers you can choose from: </p> <ul> <li>Normal Layer: All the filtered geoobjects will be shown as their original geometry</li> <li>Clustered Layer: For a better performance, objects that are near each other can be automatically grouped into a cluster that will be shown as a point indicating the number of objects inside it. In this layer, polygons that are very small on your current zoom level will also be deflated into markers for better visibility.</li> </ul> 2D View Map (Normal Layer) 2D View Map Clustered"},{"location":"Application.html#chart-visualisations","title":"Chart Visualisations","text":"<p>Additionally to the 2D View Module, this module can visualise the custom attributes of your objects.</p> <p>For now, only the bar chart is implemented. Further chart types will follow in the next release. Here, all your selected observations are shown as a bar. The value of this bar is calculated with the chosen operator and field. The field has to be a number value to be calculated successfully. Each bar is divided into all available geoobject types for a more detailed view. For operators, the following are included:</p> <ul> <li>Sum: All values of the chosen attribute are summed up.</li> <li>Average: The average value of the chosen attribute.</li> <li>Min: Only the smallest value of the attribute will be shown.</li> <li>Max: Only the biggest value of the attribute will be shown.</li> <li>Count: The total count of objects. If a field is selected, only objects that have the chosen field are counted.</li> </ul> <p>As an additional control option, you can click on a bar to select this corresponding observation and only show its content in the 2D View module.</p>"},{"location":"Application.html#32-user-input","title":"3.2 User Input","text":"<p>Next to the visualisation modules, user input modules are important to guarantee a responsive dashboard. They support functionality to filter your observations with time-based selection options.</p>"},{"location":"Application.html#date-range-calendar","title":"Date Range Calendar","text":"<p>With this module, you can choose a date range so that only observations that fall into this time-interval will be shown. Inside of the calendar, all days where an observation took place are marked with a small dot for better navigation. For this, only the start datetime of each observation is used.</p> <p></p>"},{"location":"Application.html#observation-slider","title":"Observation Slider","text":"<p>Other than the date range module that takes care of a broad selection, the observation slider lets you define a more detailed selection. All the observations that fall into your chosen date range are shown on the slider. You have the option to then choose between the Single and Range mode:</p> <ul> <li>Single: Only one observation is selected at a time. This can be useful if you are interested in the number and attributes of objects at this specific point in time such as bees at a certain time for example.</li> <li>Range: You can specify a start- and end-observation. For example, if you are interested in visualising all objects detected within a time fram such as rockfalls within a given month, this mode can be used.</li> </ul> <p></p>"},{"location":"Application.html#4-other-functionality","title":"4 Other Functionality","text":""},{"location":"Application.html#41-color-assignment","title":"4.1 Color Assignment","text":"<p>On the dashboard page, you can also freely adjust the colors of each type of geoobject with the \"Assign Colors\" button.</p>"},{"location":"Application.html#42-file-upload","title":"4.2 File Upload","text":"<p>If you want to visualise data on-the-fly with the dashboard, instead of setting up and uploading to a server, you can temporarily upload the input data into the dashboard directly. The selected input file is not saved and will be lost on refresh and also if you share the permalink it will not be included.</p>"},{"location":"Application.html#43-exportdownload-by-map-extent","title":"4.3 Export/Download by Map Extent","text":"<p>With this button, you can download a subset of you data. Only geoobjects that you selected and that are currently visible in the 2D View Map will be exported in the correct data format of the dashboard.</p>"},{"location":"Application.html#5-project-structure","title":"5 Project Structure","text":"<p>This project is organized into several main directories and files, each serving a specific purpose:</p> <ul> <li>/src: Contains the main source code for the application<ul> <li>/components: The React components, including the different dashboard modules.</li> <li>/fourdgeo: Python backend utilities and functions needed for the example notebooks.</li> <li>/pages: The 2 pages of the application.</li> <li>/styles: Includes the main theme of the dashboard.</li> <li>/utils: Utility functions for the dashboard like the http fetcher.</li> </ul> </li> <li>/public: Contains the <code>config.json</code> file for easy customization.</li> </ul>"},{"location":"Application.html#6-examples-data-preparation-scripts","title":"6 Examples: Data Preparation Scripts","text":"<p>You can look at a few tutorials and example data preparation scripts in the Example Notebooks section of this documentation to make your own data compatible with the dashboard:</p> <ul> <li>Beehive monitoring</li> <li>Rockfall monitoring</li> <li>Branch evolution</li> </ul>"},{"location":"beehive.html","title":"Bee monitoring","text":"<p>Related publication:</p> <ul> <li>Meyer, J. S., Tabernig, R., &amp; H\u00f6fle, B. (2025). Detection of honey bees (Apis mellifera) in hypertemporal LiDAR point cloud time series to extract bee activity zones and times. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, X-G-2025, 583\u2013590. https://doi.org/10.5194/isprs-annals-x-g-2025-583-2025</li> </ul> In\u00a0[\u00a0]: Copied! <pre>import vapc\nimport numpy as np\nimport os\nimport sys\nimport json\nsys.path.insert(0, \"../src\")\nfrom fourdgeo import projection\nfrom fourdgeo import utilities\n\n# File download and handling\nfrom pathlib import Path\nimport pooch\nfrom tqdm import tqdm\n\n# Clustering\nfrom sklearn.cluster import DBSCAN\n\n# Image handling\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageFont, ImageSequence\nfrom shapely.geometry import shape\n\n# Random Classification\nimport random\n\nvapc.enable_trace(False)\nvapc.enable_timeit(False)\n</pre> import vapc import numpy as np import os import sys import json sys.path.insert(0, \"../src\") from fourdgeo import projection from fourdgeo import utilities  # File download and handling from pathlib import Path import pooch from tqdm import tqdm  # Clustering from sklearn.cluster import DBSCAN  # Image handling import matplotlib.pyplot as plt from PIL import Image, ImageDraw, ImageFont, ImageSequence from shapely.geometry import shape  # Random Classification import random  vapc.enable_trace(False) vapc.enable_timeit(False) In\u00a0[2]: Copied! <pre># Handle file download/reading here\ndata_url = \"https://zenodo.org/api/records/16153369/files/beehive.zip/content\"\ndata_hash = \"ae229b9f870cd102d6aebaf9f75cf775049759ac3d75edfda8f596705a8e45b8\"\nfile_name = \"beehive.zip\"\ndata_folder = \"data/beehive\"\n\nif not Path(data_folder).exists():\n    fnames = pooch.retrieve(url=data_url,\n                            known_hash=data_hash,\n                            path=\"./\",\n                            fname=file_name,\n                            processor=pooch.Unzip(extract_dir=data_folder),\n                            progressbar=True)\n    os.remove(file_name)\n</pre> # Handle file download/reading here data_url = \"https://zenodo.org/api/records/16153369/files/beehive.zip/content\" data_hash = \"ae229b9f870cd102d6aebaf9f75cf775049759ac3d75edfda8f596705a8e45b8\" file_name = \"beehive.zip\" data_folder = \"data/beehive\"  if not Path(data_folder).exists():     fnames = pooch.retrieve(url=data_url,                             known_hash=data_hash,                             path=\"./\",                             fname=file_name,                             processor=pooch.Unzip(extract_dir=data_folder),                             progressbar=True)     os.remove(file_name) In\u00a0[3]: Copied! <pre>observations = {\"observations\": []}\ncluster_files = []\n\n# Gather &amp; sort only the .laz files\nlaz_paths = list(Path(data_folder).glob(\"*[!k].laz\")) # Get all the files except the mask\nlaz_paths = sorted(laz_paths)\n\nvoxel_size = 0.05\n\ndh_mask = vapc.DataHandler(Path(data_folder) / \"mask.laz\")\ndh_mask.load_las_files()\n\nvp_mask = vapc.Vapc(voxel_size=voxel_size, return_at=\"center_of_voxel\")\nvp_mask.get_data_from_data_handler(dh_mask)\nvp_mask.voxel_index = False\n\nfor epoch_id, laz_path in enumerate(laz_paths):\n    dh_epoch = vapc.DataHandler(laz_path)\n    dh_epoch.load_las_files()\n    dh_epoch.df = dh_epoch.df.loc[:, ['X','Y','Z','intensity','gps_time']]  # Only keeping xyz, intensity and GPS time\n\n    ## 1. Isolate the bees\n    vp_epoch = vapc.Vapc(voxel_size=voxel_size, return_at=\"center_of_voxel\")\n    vp_epoch.get_data_from_data_handler(dh_epoch)\n    vp_epoch.select_by_mask(vp_mask, segment_in_or_out=\"out\")    # &lt;-- select_by_mask \"out\"\n    dh_epoch.df = vp_epoch.df\n\n    masked_pc_path = os.path.join(f\"out/beehive/masked_{epoch_id:02d}_vox_{int(voxel_size*1000):03d}.laz\")\n    dh_epoch.save_as_las(masked_pc_path)\n\n    ## 2. Spatial clustering\n    coords = dh_epoch.df[[\"X\", \"Y\", \"Z\"]].to_numpy()\n    clustering = DBSCAN(eps=0.1, min_samples=4).fit(coords)\n    cluster = clustering.labels_\n    dh_epoch.df[\"cluster\"] = cluster\n    dh_epoch.df = dh_epoch.df[dh_epoch.df.cluster != -1]    # Dropping the points with a cluster value of -1\n    outfile = masked_pc_path.replace(\".laz\", \"_clustered.laz\")\n    dh_epoch.save_as_las(outfile)\n    cluster_files.append(outfile)\n</pre> observations = {\"observations\": []} cluster_files = []  # Gather &amp; sort only the .laz files laz_paths = list(Path(data_folder).glob(\"*[!k].laz\")) # Get all the files except the mask laz_paths = sorted(laz_paths)  voxel_size = 0.05  dh_mask = vapc.DataHandler(Path(data_folder) / \"mask.laz\") dh_mask.load_las_files()  vp_mask = vapc.Vapc(voxel_size=voxel_size, return_at=\"center_of_voxel\") vp_mask.get_data_from_data_handler(dh_mask) vp_mask.voxel_index = False  for epoch_id, laz_path in enumerate(laz_paths):     dh_epoch = vapc.DataHandler(laz_path)     dh_epoch.load_las_files()     dh_epoch.df = dh_epoch.df.loc[:, ['X','Y','Z','intensity','gps_time']]  # Only keeping xyz, intensity and GPS time      ## 1. Isolate the bees     vp_epoch = vapc.Vapc(voxel_size=voxel_size, return_at=\"center_of_voxel\")     vp_epoch.get_data_from_data_handler(dh_epoch)     vp_epoch.select_by_mask(vp_mask, segment_in_or_out=\"out\")    # &lt;-- select_by_mask \"out\"     dh_epoch.df = vp_epoch.df      masked_pc_path = os.path.join(f\"out/beehive/masked_{epoch_id:02d}_vox_{int(voxel_size*1000):03d}.laz\")     dh_epoch.save_as_las(masked_pc_path)      ## 2. Spatial clustering     coords = dh_epoch.df[[\"X\", \"Y\", \"Z\"]].to_numpy()     clustering = DBSCAN(eps=0.1, min_samples=4).fit(coords)     cluster = clustering.labels_     dh_epoch.df[\"cluster\"] = cluster     dh_epoch.df = dh_epoch.df[dh_epoch.df.cluster != -1]    # Dropping the points with a cluster value of -1     outfile = masked_pc_path.replace(\".laz\", \"_clustered.laz\")     dh_epoch.save_as_las(outfile)     cluster_files.append(outfile) In\u00a0[4]: Copied! <pre>configuration = {\n    \"project_setting\": {\n        \"project_name\": \"Beehive\",\n        \"output_folder\": \"./out/beehive\",\n        \"temporal_format\": \"%y%m%d_%H%M%S\",\n        \"silent_mode\": True,\n        \"include_timestamp\": False\n    },\n    \"pc_projection\": {\n        \"pc_path\": \"\",\n        \"make_range_image\": True,\n        \"make_color_image\": False,\n        \"top_view\": False,\n        \"save_rot_pc\": False,\n        \"resolution_cm\": 1.0,\n        \"camera_position\": [\n            0.0,\n            0.0,\n            0.0\n        ],\n        \"rgb_light_intensity\": 100,\n        \"range_light_intensity\": 10,\n        \"epsg\": None\n    }\n}\n</pre> configuration = {     \"project_setting\": {         \"project_name\": \"Beehive\",         \"output_folder\": \"./out/beehive\",         \"temporal_format\": \"%y%m%d_%H%M%S\",         \"silent_mode\": True,         \"include_timestamp\": False     },     \"pc_projection\": {         \"pc_path\": \"\",         \"make_range_image\": True,         \"make_color_image\": False,         \"top_view\": False,         \"save_rot_pc\": False,         \"resolution_cm\": 1.0,         \"camera_position\": [             0.0,             0.0,             0.0         ],         \"rgb_light_intensity\": 100,         \"range_light_intensity\": 10,         \"epsg\": None     } } In\u00a0[5]: Copied! <pre>pc = laz_paths[0]\n\ndh_epoch = vapc.DataHandler(pc)\ndh_epoch.load_las_files()\n\n# Get the background scene\nvp_epoch = vapc.Vapc(voxel_size=voxel_size)\nvp_epoch.get_data_from_data_handler(dh_epoch)\nvp_epoch.select_by_mask(vp_mask, segment_in_or_out=\"in\")    # &lt;-- select_by_mask \"in\"\ndh_epoch.df = vp_epoch.df\n\nbg_pc_path = os.path.join(f\"out/beehive/background_pc.laz\")\ndh_epoch.save_as_las(bg_pc_path)\n\nconfiguration['pc_projection']['pc_path'] = bg_pc_path\nproject_name = configuration['project_setting']['project_name']\noutput_folder = configuration['project_setting']['output_folder']\n</pre> pc = laz_paths[0]  dh_epoch = vapc.DataHandler(pc) dh_epoch.load_las_files()  # Get the background scene vp_epoch = vapc.Vapc(voxel_size=voxel_size) vp_epoch.get_data_from_data_handler(dh_epoch) vp_epoch.select_by_mask(vp_mask, segment_in_or_out=\"in\")    # &lt;-- select_by_mask \"in\" dh_epoch.df = vp_epoch.df  bg_pc_path = os.path.join(f\"out/beehive/background_pc.laz\") dh_epoch.save_as_las(bg_pc_path)  configuration['pc_projection']['pc_path'] = bg_pc_path project_name = configuration['project_setting']['project_name'] output_folder = configuration['project_setting']['output_folder']  In\u00a0[\u00a0]: Copied! <pre>background_projection = projection.PCloudProjection(\n    configuration = configuration,\n    project_name = project_name,\n    projected_image_folder = output_folder,\n)\n(\n    ref_h_fov, ref_v_fov, ref_anchor_point_xyz, \n    ref_h_img_res, ref_v_img_res\n) = background_projection.project_pc(buffer_m = 0.25)\n\nbg_img = background_projection.bg_image_filename[0]\n</pre>  background_projection = projection.PCloudProjection(     configuration = configuration,     project_name = project_name,     projected_image_folder = output_folder, ) (     ref_h_fov, ref_v_fov, ref_anchor_point_xyz,      ref_h_img_res, ref_v_img_res ) = background_projection.project_pc(buffer_m = 0.25)  bg_img = background_projection.bg_image_filename[0] In\u00a0[7]: Copied! <pre>image_path = background_projection.bg_image_filename[0]\nfilename = str.split(image_path, \".tif\")[0]\ntry:\n    with Image.open(image_path) as im:\n        for i, page in enumerate(ImageSequence.Iterator(im)):\n            out_path = filename + \".png\"\n            if not os.path.isfile(out_path):\n                try:\n                    page.save(out_path)\n                except:\n                    print(out_path)\n        png_image = out_path\nexcept:\n    print(filename)\n</pre> image_path = background_projection.bg_image_filename[0] filename = str.split(image_path, \".tif\")[0] try:     with Image.open(image_path) as im:         for i, page in enumerate(ImageSequence.Iterator(im)):             out_path = filename + \".png\"             if not os.path.isfile(out_path):                 try:                     page.save(out_path)                 except:                     print(out_path)         png_image = out_path except:     print(filename) In\u00a0[8]: Copied! <pre>img_path = r\"../docs/out/beehive/Beehive_RangeImage.tif\"\n\n# Load and display TIFF image\nimg = Image.open(img_path)\nplt.figure(figsize=(12, 8))\nplt.imshow(img)\nplt.axis('off')\nplt.show()\n</pre> img_path = r\"../docs/out/beehive/Beehive_RangeImage.tif\"  # Load and display TIFF image img = Image.open(img_path) plt.figure(figsize=(12, 8)) plt.imshow(img) plt.axis('off') plt.show() In\u00a0[\u00a0]: Copied! <pre>for epoch_id, cluster_file in enumerate(cluster_files):\n    geoObjects = []\n    dh_cluster = vapc.DataHandler(cluster_file)\n    dh_cluster.load_las_files()\n\n    # get cluster center from each cluster (each bee)\n    cluster_centers = dh_cluster.df.groupby('cluster').mean().reset_index().to_numpy()\n    columns = dh_cluster.df.groupby('cluster').mean().reset_index().columns\n    cluster_idx = columns.get_loc('cluster')\n    intensity_idx = columns.get_loc('intensity')\n    gps_time_idx = columns.get_loc('gps_time')\n\n    # extract time from filename\n    t_min = t_max = utilities.iso_timestamp(laz_paths[epoch_id].stem.split(\" \")[-3])\n\n    # create json object for each line\n    for i, cluster_center in enumerate(cluster_centers):\n        geoObject = {}\n        geoObject[\"id\"] = f\"{epoch_id}{i:04d}\"\n        geoObject[\"type\"] = random.choices([\"Bee\", \"Hornet\"], weights=[0.97, 0.03])[0]\n        geoObject[\"dateTime\"] = t_min\n        geoObject[\"geometry\"] = {\n            \"type\": \"\",\n            \"coordinates\": [\n                cluster_center[1:4].tolist()\n            ]\n        }\n        geoObject[\"customAttributes\"] = {\n            \"cluster_id\":  cluster_center[cluster_idx],\n            \"intensity\": cluster_center[intensity_idx],\n            \"gps_time\": cluster_center[gps_time_idx],\n            \"epoch_id\": epoch_id\n        }\n        \n        geoObjects.append(geoObject)\n\n    observations[\"observations\"].append({\n        \"startDateTime\": t_min,\n        \"endDateTime\": t_max,\n        \"geoObjects\": geoObjects,\n        \"backgroundImageData\": {\n            \"url\": bg_img,\n            \"height\": Image.open(bg_img).convert(\"RGB\").size[1],\n            \"width\": Image.open(bg_img).convert(\"RGB\").size[0]\n        },\n    })\n</pre> for epoch_id, cluster_file in enumerate(cluster_files):     geoObjects = []     dh_cluster = vapc.DataHandler(cluster_file)     dh_cluster.load_las_files()      # get cluster center from each cluster (each bee)     cluster_centers = dh_cluster.df.groupby('cluster').mean().reset_index().to_numpy()     columns = dh_cluster.df.groupby('cluster').mean().reset_index().columns     cluster_idx = columns.get_loc('cluster')     intensity_idx = columns.get_loc('intensity')     gps_time_idx = columns.get_loc('gps_time')      # extract time from filename     t_min = t_max = utilities.iso_timestamp(laz_paths[epoch_id].stem.split(\" \")[-3])      # create json object for each line     for i, cluster_center in enumerate(cluster_centers):         geoObject = {}         geoObject[\"id\"] = f\"{epoch_id}{i:04d}\"         geoObject[\"type\"] = random.choices([\"Bee\", \"Hornet\"], weights=[0.97, 0.03])[0]         geoObject[\"dateTime\"] = t_min         geoObject[\"geometry\"] = {             \"type\": \"\",             \"coordinates\": [                 cluster_center[1:4].tolist()             ]         }         geoObject[\"customAttributes\"] = {             \"cluster_id\":  cluster_center[cluster_idx],             \"intensity\": cluster_center[intensity_idx],             \"gps_time\": cluster_center[gps_time_idx],             \"epoch_id\": epoch_id         }                  geoObjects.append(geoObject)      observations[\"observations\"].append({         \"startDateTime\": t_min,         \"endDateTime\": t_max,         \"geoObjects\": geoObjects,         \"backgroundImageData\": {             \"url\": bg_img,             \"height\": Image.open(bg_img).convert(\"RGB\").size[1],             \"width\": Image.open(bg_img).convert(\"RGB\").size[0]         },     }) In\u00a0[\u00a0]: Copied! <pre>from fourdgeo import projection\nlist_observation_projection = []\nfor epoch_id, observation in enumerate(observations['observations']):\n    observation_projection = projection.ProjectChange(observation=observation,\n                            project_name=f\"{project_name}_{epoch_id}_{epoch_id+1}\",\n                            projected_image_path=background_projection.bg_image_filename[0],\n                            projected_events_folder=output_folder,\n                            epsg=None)\n\n    observation_projection.project_change()\n    list_observation_projection.append(observation_projection)\n</pre> from fourdgeo import projection list_observation_projection = [] for epoch_id, observation in enumerate(observations['observations']):     observation_projection = projection.ProjectChange(observation=observation,                             project_name=f\"{project_name}_{epoch_id}_{epoch_id+1}\",                             projected_image_path=background_projection.bg_image_filename[0],                             projected_events_folder=output_folder,                             epsg=None)      observation_projection.project_change()     list_observation_projection.append(observation_projection) In\u00a0[11]: Copied! <pre>frames = []\ngif_path = \"../docs/img/beehive_projections_plus_observations.gif\"\nfont = ImageFont.load_default(size = 50)\nellipse_size = 8\n\nfor enum, observation_projection in enumerate(list_observation_projection):\n    frm = Image.open(bg_img).convert(\"RGB\")\n    draw = ImageDraw.Draw(frm)\n    draw.text((50, 1300), f\"Epoch: {enum}\", fill=(255, 255, 255), font=font)\n\n    # Load geojson\n    with open(observation_projection.geojson_name, 'r') as f:\n        geojson_data = json.load(f)\n\n    for feature in geojson_data[\"features\"]:\n        geom = shape(feature[\"geometry\"])\n        \n        coords = [(int(x), -int(y)) for x, y in geom.coords]\n\n        x, y = geom.coords[0][0], geom.coords[0][1] * -1\n        draw.ellipse([x-ellipse_size//2, y-ellipse_size//2, x+ellipse_size//2, y+ellipse_size//2], fill=\"yellow\")\n\n    frames.append(frm)\n    \n\nframes[0].save(\n    gif_path,\n    save_all=True,\n    append_images=frames[1:],\n    duration=600,\n    loop=0\n)\n</pre> frames = [] gif_path = \"../docs/img/beehive_projections_plus_observations.gif\" font = ImageFont.load_default(size = 50) ellipse_size = 8  for enum, observation_projection in enumerate(list_observation_projection):     frm = Image.open(bg_img).convert(\"RGB\")     draw = ImageDraw.Draw(frm)     draw.text((50, 1300), f\"Epoch: {enum}\", fill=(255, 255, 255), font=font)      # Load geojson     with open(observation_projection.geojson_name, 'r') as f:         geojson_data = json.load(f)      for feature in geojson_data[\"features\"]:         geom = shape(feature[\"geometry\"])                  coords = [(int(x), -int(y)) for x, y in geom.coords]          x, y = geom.coords[0][0], geom.coords[0][1] * -1         draw.ellipse([x-ellipse_size//2, y-ellipse_size//2, x+ellipse_size//2, y+ellipse_size//2], fill=\"yellow\")      frames.append(frm)       frames[0].save(     gif_path,     save_all=True,     append_images=frames[1:],     duration=600,     loop=0 ) In\u00a0[12]: Copied! <pre>aggregated_data = utilities.DataModel([])\n\nfor (i, observation_projection) in enumerate(list_observation_projection):\n    if observation_projection is None:\n        continue\n    elif observation_projection.observation[\"geoObjects\"] is None:\n        img_size = Image.open(png_image).convert(\"RGB\").size\n        aggregated_data.observations.append(utilities.Observation(\n            startDateTime=observation_projection.observation[\"startDateTime\"],\n            endDateTime=observation_projection.observation[\"endDateTime\"],\n            geoObjects=[],\n            backgroundImageData=utilities.ImageData(\n                url=str(\"http://localhost:8001/\" + png_image).replace(\"\\\\\", \"/\"),\n                width=img_size[0],\n                height=img_size[1]\n            )\n        ))\n        continue\n    \n    with open(observation_projection.geojson_name, 'r') as f:\n        geojson_data = json.load(f)\n    \n    img_size = Image.open(png_image).convert(\"RGB\").size\n    geometry = geojson_data.get(\"features\")[0].get(\"geometry\")\n    coords = geometry.get(\"coordinates\")\n    new_observations = utilities.convert_geojson_to_datamodel(\n        geojson=geojson_data,\n        bg_img=str(\"http://localhost:8001/\" + png_image).replace(\"\\\\\", \"/\"),\n        width=img_size[0],\n        height=img_size[1]\n    )\n\n    aggregated_data.observations.extend(new_observations.observations)\n\nwith open(f\"{output_folder}/final_data_model.json\", \"w\") as f:\n    f.write(aggregated_data.toJSON())\n</pre> aggregated_data = utilities.DataModel([])  for (i, observation_projection) in enumerate(list_observation_projection):     if observation_projection is None:         continue     elif observation_projection.observation[\"geoObjects\"] is None:         img_size = Image.open(png_image).convert(\"RGB\").size         aggregated_data.observations.append(utilities.Observation(             startDateTime=observation_projection.observation[\"startDateTime\"],             endDateTime=observation_projection.observation[\"endDateTime\"],             geoObjects=[],             backgroundImageData=utilities.ImageData(                 url=str(\"http://localhost:8001/\" + png_image).replace(\"\\\\\", \"/\"),                 width=img_size[0],                 height=img_size[1]             )         ))         continue          with open(observation_projection.geojson_name, 'r') as f:         geojson_data = json.load(f)          img_size = Image.open(png_image).convert(\"RGB\").size     geometry = geojson_data.get(\"features\")[0].get(\"geometry\")     coords = geometry.get(\"coordinates\")     new_observations = utilities.convert_geojson_to_datamodel(         geojson=geojson_data,         bg_img=str(\"http://localhost:8001/\" + png_image).replace(\"\\\\\", \"/\"),         width=img_size[0],         height=img_size[1]     )      aggregated_data.observations.extend(new_observations.observations)  with open(f\"{output_folder}/final_data_model.json\", \"w\") as f:     f.write(aggregated_data.toJSON())"},{"location":"beehive.html#beehive-monitoring","title":"Beehive monitoring\u00b6","text":"<p>Notebook contributors: William Albert, Hannah Weiser, Ronald Tabernig, July 2025</p> <p>This notebook demonstrates the preparation of the beehive monitoring example, including the bee detection workflow. The dataset contains 6 LiDAR scans of a beehive and the surrounding, each captured every 40 seconds on 14 May 2025.</p> <p>For our use case, a point cloud mask was created containing the background points, i.e., all points not reflected from the flying bees. To speed up processing, the background points in each epoch were thinned using spatial subsampling (0.01 m), while the bee points were kept at their original resolution.</p>"},{"location":"beehive.html#imports","title":"Imports\u00b6","text":""},{"location":"beehive.html#get-the-data","title":"Get the data\u00b6","text":""},{"location":"beehive.html#bee-detection","title":"Bee detection\u00b6","text":"<p>For the bee detection, we first isolate the bees from the rest of the scene by masking the trees, beehive, ground, etc. using the provided point cloud mask (<code>mask.laz</code>). Then, we cluster the bee points using DBSCAN and write out the clustered point clouds.</p>"},{"location":"beehive.html#projections-background-point-cloud","title":"Projections (background point cloud)\u00b6","text":""},{"location":"beehive.html#prepare-the-configuration-file","title":"Prepare the configuration file\u00b6","text":"<p>We use a configuration dictionary that contains general project settings like the <code>output_folder</code> and the relevant settings for the point cloud projection. For the projection, parameters like the <code>camera_position</code> and the <code>resolution_cm</code> are essential.</p>"},{"location":"beehive.html#generate-the-background-image","title":"Generate the background image\u00b6","text":"<p>We now generate the background image. For this, we are using classes and functions from the <code>fourdgeo</code> library. The class <code>PCloudProjection</code> directly takes our configuration file as input and writes the generated image to our specified <code>output_folder</code>.</p>"},{"location":"beehive.html#convert-tif-image-to-png-image","title":"Convert .tif Image to .png Image\u00b6","text":"<p>Because the dashboard (currently) does not support TIF files, we need to convert the generated background image to the PNG format.</p>"},{"location":"beehive.html#dispay-the-background-image","title":"Dispay the background image\u00b6","text":"<p>Let's have a look at how the point cloud looks like from the scanner view.</p>"},{"location":"beehive.html#projections-bee-observations","title":"Projections (bee observations)\u00b6","text":"<p>We describe each bee cluster by its centroid. In the following, we extract the center point for each center and create <code>geoObjects</code>, one for each cluster. For the purpose of showcasing, we randomly assign each extracted geoObject either the <code>Bee</code> or <code>Hornet</code> type.</p>"},{"location":"beehive.html#project-the-bee-clusters-onto-the-image-background","title":"Project the bee clusters onto the image background\u00b6","text":"<p>Here, we project the bee observations onto the background image using the <code>ProjectChange</code> class. The <code>observation</code> GeoJSON files are written to the <code>output_folder</code>.</p>"},{"location":"beehive.html#display-the-bee-clusters-in-the-site","title":"Display the bee clusters in the site\u00b6","text":"<p>Finally, we generate a GIF of the time series and display the bee clusters using the projected points.</p>"},{"location":"beehive.html#extract-the-final-json","title":"Extract the final JSON\u00b6","text":"<p>In order to include this data into the dashboard, we now need to convert the created geojson data to the dashboard data model. For this, we iterate through all geojson files and create their observation objects and the aggregate them into one final data model object and store it in the <code>output_folder</code>. This files can then be loaded with the 4DGeo Dashboard.</p> <p>Note: The path to the background image files has to be a working url. In this example, we use the temporary hosted localhost, explained in this section. Later this can and should be replaced by an actual server containing the files.</p>"},{"location":"beehive.html#visualise-the-data-in-the-dashboard","title":"Visualise the data in the dashboard\u00b6","text":"<p>To see our results in the actual dashboard, we need to host the created json file to make it accessbile. As a quick and easy solution, we can use the http.server python library. The python script <code>server-host.py</code> hosts all the files in this directory. So in order to setup this local hosting, we need navigate to the <code>4DGeo/docs</code> folder to execute the following command in a commandline:</p> <p><code>python server_host.py</code></p> <p>Lastly, inside of the dashboard, set the data source to <code>http://localhost:8001/out/rockfall_monitoring/final_data_model.json</code>.</p>"},{"location":"branch_evolution.html","title":"Branch evolution","text":"<p>Related publications:</p> <ul> <li>Di Wang, Puttonen, E., &amp; Casella, E. (2022). PlantMove: A tool for quantifying motion fields of plant movements from point cloud time series. International Journal of Applied Earth Observation and Geoinformation, 110, 102781. https://doi.org/10.1016/j.jag.2022.102781</li> <li>Albert, W., Weiser, H., Tabernig, R., &amp; H\u00f6fle, B. (2025). Wind during terrestrial laser scanning of trees: Simulation-based assessment of effects on point cloud features and leaf-wood classification. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, X-G-2025, 25\u201332. https://doi.org/10.5194/isprs-annals-x-g-2025-25-2025</li> <li>Weiser, H., &amp; H\u00f6fle, B. (2025). Advancing vegetation monitoring with virtual laser scanning of dynamic scenes (VLS-4D): Opportunities, implementations and future perspectives. https://doi.org/10.31223/x51q5v</li> </ul> In\u00a0[1]: Copied! <pre>import os\nimport sys\nimport json\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import KDTree\nimport pandas as pd\nimport laspy\n\nimport vapc\nfrom vapc.las_split_append_merge import las_merge\nsys.path.insert(0, \"../src\")\nfrom fourdgeo import projection\nfrom fourdgeo import utilities\n\n# File download and handling\nfrom pathlib import Path\nimport pooch\nfrom tqdm import tqdm\n\n# Image and geometry handling\nfrom PIL import Image, ImageDraw, ImageFont, ImageSequence\nfrom IPython.display import HTML\nfrom shapely.geometry import shape\n</pre> import os import sys import json  import numpy as np import matplotlib.pyplot as plt from scipy.spatial import KDTree import pandas as pd import laspy  import vapc from vapc.las_split_append_merge import las_merge sys.path.insert(0, \"../src\") from fourdgeo import projection from fourdgeo import utilities  # File download and handling from pathlib import Path import pooch from tqdm import tqdm  # Image and geometry handling from PIL import Image, ImageDraw, ImageFont, ImageSequence from IPython.display import HTML from shapely.geometry import shape In\u00a0[2]: Copied! <pre># Handle file download/reading here\ndata_url = \"https://zenodo.org/api/records/16153369/files/branch_evolution.zip/content\"\ndata_hash = \"645670e7f71227df47cf1a41a281aaf052a299fc5462a048503d33b6db1009be\"\nfile_name = \"branch_evolution.zip\"\ndata_folder = \"data/branch_evolution\"\n\nif not Path(data_folder).exists():\n    fnames = pooch.retrieve(url=data_url,\n                            known_hash=data_hash,\n                            path=\"./\",\n                            fname=file_name,\n                            processor=pooch.Unzip(extract_dir=data_folder),\n                            progressbar=True)\n    os.remove(file_name)\n</pre> # Handle file download/reading here data_url = \"https://zenodo.org/api/records/16153369/files/branch_evolution.zip/content\" data_hash = \"645670e7f71227df47cf1a41a281aaf052a299fc5462a048503d33b6db1009be\" file_name = \"branch_evolution.zip\" data_folder = \"data/branch_evolution\"  if not Path(data_folder).exists():     fnames = pooch.retrieve(url=data_url,                             known_hash=data_hash,                             path=\"./\",                             fname=file_name,                             processor=pooch.Unzip(extract_dir=data_folder),                             progressbar=True)     os.remove(file_name) In\u00a0[3]: Copied! <pre>laz_files_branches = list(Path(data_folder).glob(\"*_branch.laz\"))\nlaz_files_rest = list(Path(data_folder).glob(\"*_rest.laz\"))\n\nlas_b0 = laspy.read(laz_files_branches[0])\npc_b0 = np.c_[las_b0.x, las_b0.y, las_b0.z]\nlas_b6 = laspy.read(laz_files_branches[6])\npc_b6 = np.c_[las_b6.x, las_b6.y, las_b6.z]\nlas_r0 = laspy.read(laz_files_rest[0])\npc_r0 = np.c_[las_r0.x, las_r0.y, las_r0.z]\nlas_r6 = laspy.read(laz_files_rest[6])\npc_r6 = np.c_[las_r6.x, las_r6.y, las_r6.z]\n\nfig = plt.figure(figsize=(16,8))\n\n# Scatter plot\nax = fig.add_subplot(121, projection=\"3d\")\nsc1 = ax.scatter(\n    pc_b0[::5, 0],\n    pc_b0[::5, 1],\n    pc_b0[::5, 2],\n    color=\"black\", s=0.02\n)\nsc1_2 = ax.scatter(\n    pc_r0[::5, 0],\n    pc_r0[::5, 1],\n    pc_r0[::5, 2],\n    c=pc_r0[::5, 2], s=0.02\n)\n\nax2 = fig.add_subplot(122, projection=\"3d\")\nsc2 = ax2.scatter(\n    pc_b6[::5, 0],\n    pc_b6[::5, 1],\n    pc_b6[::5, 2],\n    color=\"black\", s=0.02\n)\nsc2_2 = ax2.scatter(\n    pc_r6[::5, 0],\n    pc_r6[::5, 1],\n    pc_r6[::5, 2],\n    c=pc_r6[::5, 2], s=0.02\n)\n\n# Add axis labels.\nax.set_zlabel(\"[m]\")\nax.set_xticklabels([])\nax.set_yticklabels([])\nax.set_title(\"2025-03-27\")\nax2.set_zlabel(\"[m]\")\nax2.set_xticklabels([])\nax2.set_yticklabels([])\nax2.set_title(\"2025-05-09\")\n\n# set equal axes\nbox = (np.ptp(pc_r6[:, 0]), np.ptp(pc_r6[:, 1]), np.ptp(pc_r6[:, 2]))\nax.set_box_aspect(box)\nax2.set_box_aspect(box)\n\n# Set title.\n# Set view\nax.view_init(elev=5, azim=10, roll=0)\nax2.view_init(elev=5, azim=10, roll=0)\n\n# Display results\nfig.suptitle(\"Comparison of first and last epoch\", fontsize=18)\nplt.show()\n</pre> laz_files_branches = list(Path(data_folder).glob(\"*_branch.laz\")) laz_files_rest = list(Path(data_folder).glob(\"*_rest.laz\"))  las_b0 = laspy.read(laz_files_branches[0]) pc_b0 = np.c_[las_b0.x, las_b0.y, las_b0.z] las_b6 = laspy.read(laz_files_branches[6]) pc_b6 = np.c_[las_b6.x, las_b6.y, las_b6.z] las_r0 = laspy.read(laz_files_rest[0]) pc_r0 = np.c_[las_r0.x, las_r0.y, las_r0.z] las_r6 = laspy.read(laz_files_rest[6]) pc_r6 = np.c_[las_r6.x, las_r6.y, las_r6.z]  fig = plt.figure(figsize=(16,8))  # Scatter plot ax = fig.add_subplot(121, projection=\"3d\") sc1 = ax.scatter(     pc_b0[::5, 0],     pc_b0[::5, 1],     pc_b0[::5, 2],     color=\"black\", s=0.02 ) sc1_2 = ax.scatter(     pc_r0[::5, 0],     pc_r0[::5, 1],     pc_r0[::5, 2],     c=pc_r0[::5, 2], s=0.02 )  ax2 = fig.add_subplot(122, projection=\"3d\") sc2 = ax2.scatter(     pc_b6[::5, 0],     pc_b6[::5, 1],     pc_b6[::5, 2],     color=\"black\", s=0.02 ) sc2_2 = ax2.scatter(     pc_r6[::5, 0],     pc_r6[::5, 1],     pc_r6[::5, 2],     c=pc_r6[::5, 2], s=0.02 )  # Add axis labels. ax.set_zlabel(\"[m]\") ax.set_xticklabels([]) ax.set_yticklabels([]) ax.set_title(\"2025-03-27\") ax2.set_zlabel(\"[m]\") ax2.set_xticklabels([]) ax2.set_yticklabels([]) ax2.set_title(\"2025-05-09\")  # set equal axes box = (np.ptp(pc_r6[:, 0]), np.ptp(pc_r6[:, 1]), np.ptp(pc_r6[:, 2])) ax.set_box_aspect(box) ax2.set_box_aspect(box)  # Set title. # Set view ax.view_init(elev=5, azim=10, roll=0) ax2.view_init(elev=5, azim=10, roll=0)  # Display results fig.suptitle(\"Comparison of first and last epoch\", fontsize=18) plt.show() <p>The motion vectors have been computed with PlantMove for each point in a selected branch in the point cloud. They are stored in a .npz archive. Let's look at the structure for the first observation (change between first epoch on 27 March and second epoch on 4 April 2025).</p> <p><code>cloud_x</code> is the first time step,  <code>cloud_y</code> is the second time step,  <code>motionfield</code> is the derived motion field  and <code>cloud_new</code> is the point cloud of the second time step registered onto the first time step by applying the motion vectors.</p> In\u00a0[4]: Copied! <pre>files = list(Path(data_folder).glob(\"*.npz\"))\nfiles = sorted(files)\nobs_file = files[0]\ndata = np.load(obs_file)\ncloud_x = data[\"x_original\"]  # t0\ncloud_y = data[\"y_original\"]  # t1\ncloud_new = data[\"y_new\"]  # t1 to t0\nmotionfield = data[\"motionfield\"]  # motion field from t0 to t1\nmotion_vec = motionfield[:, 3:6]\nmotion_magnitudes = np.linalg.norm(motion_vec, axis=1)\n</pre> files = list(Path(data_folder).glob(\"*.npz\")) files = sorted(files) obs_file = files[0] data = np.load(obs_file) cloud_x = data[\"x_original\"]  # t0 cloud_y = data[\"y_original\"]  # t1 cloud_new = data[\"y_new\"]  # t1 to t0 motionfield = data[\"motionfield\"]  # motion field from t0 to t1 motion_vec = motionfield[:, 3:6] motion_magnitudes = np.linalg.norm(motion_vec, axis=1) In\u00a0[5]: Copied! <pre>print(\"Motion magnitudes between t0 and t1:\\n\")\nprint(f\"{'Min:':20} {motion_magnitudes.min():.3f} m\")\nprint(f\"{'Max:':20} {motion_magnitudes.max():.3f} m\")\nprint(f\"{'Mean:':20} {motion_magnitudes.mean():.3f} m\")\nprint(f\"{'Standard deviation:':20} {motion_magnitudes.std():.3f} m\")\n</pre> print(\"Motion magnitudes between t0 and t1:\\n\") print(f\"{'Min:':20} {motion_magnitudes.min():.3f} m\") print(f\"{'Max:':20} {motion_magnitudes.max():.3f} m\") print(f\"{'Mean:':20} {motion_magnitudes.mean():.3f} m\") print(f\"{'Standard deviation:':20} {motion_magnitudes.std():.3f} m\") <pre>Motion magnitudes between t0 and t1:\n\nMin:                 0.000 m\nMax:                 0.018 m\nMean:                0.005 m\nStandard deviation:  0.003 m\n</pre> <p>We use a configuration dictionary that contains general project settings like the <code>output_folder</code> and the relevant settings for the point cloud projection. For the projection, the <code>camera_position</code> is essential, for which we choose the location of the scanner (in ETRS89, UTM zone 32 N).</p> In\u00a0[6]: Copied! <pre>configuration = {\n    \"project_setting\": {\n        \"project_name\": \"Branch_evolution\",\n        \"output_folder\": \"./out/branch_evolution\",\n        \"temporal_format\": \"%y%m%d_%H%M%S\",\n        \"silent_mode\": True,\n        \"include_timestamp\": False\n    },\n    \"pc_projection\": {\n        \"pc_path\": \"\",\n        \"make_range_image\": False,\n        \"make_color_image\": True,\n        \"top_view\": False,\n        \"save_rot_pc\": False,\n        \"resolution_cm\": 0.2,\n        \"camera_position\": [\n            475923.4099,\n            5473923.7662,\n            159.1088\n        ],\n        \"rgb_light_intensity\": 100,\n        \"range_light_intensity\": 60,\n        \"epsg\": 25832\n    }\n}\n</pre> configuration = {     \"project_setting\": {         \"project_name\": \"Branch_evolution\",         \"output_folder\": \"./out/branch_evolution\",         \"temporal_format\": \"%y%m%d_%H%M%S\",         \"silent_mode\": True,         \"include_timestamp\": False     },     \"pc_projection\": {         \"pc_path\": \"\",         \"make_range_image\": False,         \"make_color_image\": True,         \"top_view\": False,         \"save_rot_pc\": False,         \"resolution_cm\": 0.2,         \"camera_position\": [             475923.4099,             5473923.7662,             159.1088         ],         \"rgb_light_intensity\": 100,         \"range_light_intensity\": 60,         \"epsg\": 25832     } } In\u00a0[7]: Copied! <pre>laz_files_rest = sorted(laz_files_rest)\nlaz_files_branches = sorted(laz_files_branches)\n\npcs = []\n\nfor enum in np.arange(len(laz_files_rest)-1):\n    pos = str(laz_files_rest[enum]).find(\"_icp_rest\")\n    new_file_path = str(laz_files_rest[enum])[:pos]\n    with laspy.open(laz_files_branches[enum]) as las_branch_A:\n        las_branch_A = las_branch_A.read()\n        las_branch_A.red = np.full(len(las_branch_A.points), 65535)\n        las_branch_A.green = np.full(len(las_branch_A.points), 22768)\n        las_branch_A.blue = np.full(len(las_branch_A.points), 0)\n        las_branch_A.write(laz_files_branches[enum])\n\n    with laspy.open(laz_files_branches[enum+1]) as las_branch_B:\n        las_branch_B = las_branch_B.read()\n        las_branch_B.red = np.full(len(las_branch_B.points), 0)\n        las_branch_B.green = np.full(len(las_branch_B.points), 0)\n        las_branch_B.blue = np.full(len(las_branch_B.points), 65535)\n        las_branch_B.write(laz_files_branches[enum+1])\n\n    with laspy.open(laz_files_rest[enum]) as las_rest_A:\n        las_rest_A = las_rest_A.read()\n        intensities = las_rest_A.intensity\n\n        # Normalize intensities to 0-65535\n        norm = (intensities - intensities.min()) / (np.ptp(intensities) + 1e-8)\n        colors = (norm * 65535).astype(np.uint16)\n\n        # Assign grayscale color based on intensity\n        las_rest_A.red = las_rest_A.green = las_rest_A.blue = colors\n        las_rest_A.write(laz_files_rest[enum])\n\n    las_merge([laz_files_rest[enum], laz_files_branches[enum], laz_files_branches[enum+1]], f\"{new_file_path}_{enum}_{enum+1}.laz\", point_source_id=True)\n    pcs.append(f\"{new_file_path}_{enum}_{enum+1}.laz\")\n</pre> laz_files_rest = sorted(laz_files_rest) laz_files_branches = sorted(laz_files_branches)  pcs = []  for enum in np.arange(len(laz_files_rest)-1):     pos = str(laz_files_rest[enum]).find(\"_icp_rest\")     new_file_path = str(laz_files_rest[enum])[:pos]     with laspy.open(laz_files_branches[enum]) as las_branch_A:         las_branch_A = las_branch_A.read()         las_branch_A.red = np.full(len(las_branch_A.points), 65535)         las_branch_A.green = np.full(len(las_branch_A.points), 22768)         las_branch_A.blue = np.full(len(las_branch_A.points), 0)         las_branch_A.write(laz_files_branches[enum])      with laspy.open(laz_files_branches[enum+1]) as las_branch_B:         las_branch_B = las_branch_B.read()         las_branch_B.red = np.full(len(las_branch_B.points), 0)         las_branch_B.green = np.full(len(las_branch_B.points), 0)         las_branch_B.blue = np.full(len(las_branch_B.points), 65535)         las_branch_B.write(laz_files_branches[enum+1])      with laspy.open(laz_files_rest[enum]) as las_rest_A:         las_rest_A = las_rest_A.read()         intensities = las_rest_A.intensity          # Normalize intensities to 0-65535         norm = (intensities - intensities.min()) / (np.ptp(intensities) + 1e-8)         colors = (norm * 65535).astype(np.uint16)          # Assign grayscale color based on intensity         las_rest_A.red = las_rest_A.green = las_rest_A.blue = colors         las_rest_A.write(laz_files_rest[enum])      las_merge([laz_files_rest[enum], laz_files_branches[enum], laz_files_branches[enum+1]], f\"{new_file_path}_{enum}_{enum+1}.laz\", point_source_id=True)     pcs.append(f\"{new_file_path}_{enum}_{enum+1}.laz\") In\u00a0[8]: Copied! <pre>images = []\nlist_background_projections = []\n\nfor enum, pc in enumerate(pcs):\n    lf = laspy.read(pc)\n    configuration['pc_projection']['pc_path'] = pc\n    project_name = configuration['project_setting']['project_name']\n    output_folder = configuration['project_setting']['output_folder']\n    \n    background_projection = projection.PCloudProjection(\n        configuration = configuration,\n        project_name = project_name,\n        projected_image_folder = output_folder\n    )\n    # First projection\n    if enum == 0:\n        (\n            ref_h_fov, ref_v_fov, ref_anchor_point_xyz, \n            ref_h_img_res, ref_v_img_res\n        ) = background_projection.project_pc(buffer_m = 0.5)\n    # Next projections using reference data\n    else:\n        background_projection.project_pc(\n            ref_theta=ref_h_fov[0],\n            ref_phi=ref_v_fov[0],\n            ref_anchor_point_xyz=ref_anchor_point_xyz,\n            ref_h_fov=ref_h_fov,\n            ref_v_fov=ref_v_fov,\n            ref_h_img_res=ref_h_img_res,\n            ref_v_img_res=ref_v_img_res,\n            buffer_m = 0.5\n        )\n\n    bg_img = background_projection.bg_image_filename[0]\n    if bg_img[0] == \".\":\n        bg_img = bg_img[2:]\n\n    outfile = bg_img.split('.')[0] + f\"_{enum}_{enum+1}.\" + bg_img.split('.')[1]\n\n    try:\n        os.rename(bg_img, outfile)\n    except FileExistsError:\n        os.remove(outfile)\n        os.rename(bg_img, outfile)\n\n    images.append(outfile)\n\n    background_projection.bg_image_filename[0] = outfile\n    list_background_projections.append(background_projection)\n</pre> images = [] list_background_projections = []  for enum, pc in enumerate(pcs):     lf = laspy.read(pc)     configuration['pc_projection']['pc_path'] = pc     project_name = configuration['project_setting']['project_name']     output_folder = configuration['project_setting']['output_folder']          background_projection = projection.PCloudProjection(         configuration = configuration,         project_name = project_name,         projected_image_folder = output_folder     )     # First projection     if enum == 0:         (             ref_h_fov, ref_v_fov, ref_anchor_point_xyz,              ref_h_img_res, ref_v_img_res         ) = background_projection.project_pc(buffer_m = 0.5)     # Next projections using reference data     else:         background_projection.project_pc(             ref_theta=ref_h_fov[0],             ref_phi=ref_v_fov[0],             ref_anchor_point_xyz=ref_anchor_point_xyz,             ref_h_fov=ref_h_fov,             ref_v_fov=ref_v_fov,             ref_h_img_res=ref_h_img_res,             ref_v_img_res=ref_v_img_res,             buffer_m = 0.5         )      bg_img = background_projection.bg_image_filename[0]     if bg_img[0] == \".\":         bg_img = bg_img[2:]      outfile = bg_img.split('.')[0] + f\"_{enum}_{enum+1}.\" + bg_img.split('.')[1]      try:         os.rename(bg_img, outfile)     except FileExistsError:         os.remove(outfile)         os.rename(bg_img, outfile)      images.append(outfile)      background_projection.bg_image_filename[0] = outfile     list_background_projections.append(background_projection) In\u00a0[9]: Copied! <pre>png_images = []\n\nfor background_projection in list_background_projections:\n    image_path = background_projection.bg_image_filename[0]\n    filename = str.split(image_path, \".\")[0]\n    try:\n        with Image.open(image_path) as im:\n            for i, page in enumerate(ImageSequence.Iterator(im)):\n                out_path = filename + \".png\"\n                if not os.path.isfile(out_path):\n                    try:\n                        page.save(out_path)\n                    except:\n                        print(out_path)\n            png_images.append(out_path)\n    except:\n        print(filename)\n</pre> png_images = []  for background_projection in list_background_projections:     image_path = background_projection.bg_image_filename[0]     filename = str.split(image_path, \".\")[0]     try:         with Image.open(image_path) as im:             for i, page in enumerate(ImageSequence.Iterator(im)):                 out_path = filename + \".png\"                 if not os.path.isfile(out_path):                     try:                         page.save(out_path)                     except:                         print(out_path)             png_images.append(out_path)     except:         print(filename) <p>Let's create a GIF from the images and display it.</p> In\u00a0[10]: Copied! <pre>gif_path = \"../docs/img/tree_projections.gif\"\nframes = [Image.open(img).convert(\"RGB\") for img in images]\n\nframes[0].save(\n    gif_path,\n    save_all=True,\n    append_images=frames[1:],\n    duration=500,\n    loop=0\n)\n</pre> gif_path = \"../docs/img/tree_projections.gif\" frames = [Image.open(img).convert(\"RGB\") for img in images]  frames[0].save(     gif_path,     save_all=True,     append_images=frames[1:],     duration=500,     loop=0 ) In\u00a0[11]: Copied! <pre>if configuration[\"project_setting\"][\"silent_mode\"]:\n    vapc.enable_trace(False)\n    vapc.enable_timeit(False)\nvoxel_size = 0.05\n</pre> if configuration[\"project_setting\"][\"silent_mode\"]:     vapc.enable_trace(False)     vapc.enable_timeit(False) voxel_size = 0.05 In\u00a0[12]: Copied! <pre>project_name = configuration[\"project_setting\"][\"project_name\"]\nobservations = {\"observations\": []}\n\nfor epoch_id, file in enumerate(files):\n    geoObjects = []\n    # extract time from filenames\n    t_min = utilities.iso_timestamp(\"_\".join(file.stem.split(\"_\")[1:3]))\n    t_max = utilities.iso_timestamp(\"_\".join(file.stem.split(\"_\")[7:9]))\n\n    data = np.load(file)\n    cloud_x = data[\"x_original\"]  # t0\n    cloud_y = data[\"y_original\"]  # t1\n    cloud_new = data[\"y_new\"]  # t1 to t0\n    motionfield = data[\"motionfield\"]\n    motion_vec = motionfield[:, 3:6]\n    motion_magnitudes = np.linalg.norm(motion_vec, axis=1)\n\n    if epoch_id == 0:\n        min_point = np.min(cloud_x, axis=0)\n        local_origin = np.floor(min_point / 100) * 100\n    \n    # array to dataframe\n    df_y = pd.DataFrame(cloud_y, columns=[\"X\", \"Y\", \"Z\"])\n    df_new = pd.DataFrame(cloud_new, columns=[\"X\", \"Y\", \"Z\"])\n\n    vapc_y = vapc.Vapc(voxel_size=voxel_size, origin=local_origin.tolist())\n    vapc_y.df = df_y\n    vapc_y.compute = [\"center_of_voxel\"]\n    vapc_y.compute_requested_attributes()\n\n    vapc_new = vapc.Vapc(voxel_size=voxel_size, origin=local_origin.tolist())\n    vapc_new.df = df_new\n    vapc_new.compute = [\"center_of_voxel\"]\n    vapc_new.compute_requested_attributes()\n    \n    if epoch_id == 0:\n        seed_points = np.array((vapc_new.df[\"center_x\"].values, vapc_new.df[\"center_y\"].values, vapc_new.df[\"center_z\"].values)).T\n        seed_points = np.unique(seed_points, axis=0)\n    else:\n        seed_points = pts_y_original\n    \n    # get nearest neighbours to seed points in cloud_new\n    tree_ynew = KDTree(cloud_new)\n\n    dist, idx_yn = tree_ynew.query(seed_points, k=1)\n\n    # get points\n    pts_y_original = cloud_y[idx_yn, :]\n    pts_y_new = cloud_new[idx_yn, :]\n\n    # create lines from nearest points to seed in cloud y and corresponding points in cloud x\n    lines = np.hstack((pts_y_original, pts_y_new))\n\n    # create json object for each line\n    for i in range(lines.shape[0]):\n        geoObject = {}\n        geoObject[\"id\"] = f\"{epoch_id}{i:04d}\"\n        geoObject[\"type\"] = \"motion_vector\"\n        geoObject[\"dateTime\"] = t_min\n        geoObject[\"geometry\"] = {\n            \"type\": \"\",\n            \"coordinates\": [\n                lines[i, 0:3].tolist(),\n                lines[i, 3:6].tolist()\n            ]\n        }\n        geoObject[\"customAttributes\"] = {\n            \"motion_magnitudes\": motion_magnitudes[i],\n            \"epoch_id\": epoch_id\n        }\n        \n        geoObjects.append(geoObject)\n\n    observations[\"observations\"].append({\n        \"startDateTime\": t_min,\n        \"endDateTime\": t_max,\n        \"geoObjects\": geoObjects,\n        \"backgroundImageData\": {\n            \"url\": list_background_projections[epoch_id].bg_image_filename[0],\n            \"height\": Image.open(images[epoch_id]).convert(\"RGB\").size[1],\n            \"width\": Image.open(images[epoch_id]).convert(\"RGB\").size[0]\n        },\n    })\n</pre> project_name = configuration[\"project_setting\"][\"project_name\"] observations = {\"observations\": []}  for epoch_id, file in enumerate(files):     geoObjects = []     # extract time from filenames     t_min = utilities.iso_timestamp(\"_\".join(file.stem.split(\"_\")[1:3]))     t_max = utilities.iso_timestamp(\"_\".join(file.stem.split(\"_\")[7:9]))      data = np.load(file)     cloud_x = data[\"x_original\"]  # t0     cloud_y = data[\"y_original\"]  # t1     cloud_new = data[\"y_new\"]  # t1 to t0     motionfield = data[\"motionfield\"]     motion_vec = motionfield[:, 3:6]     motion_magnitudes = np.linalg.norm(motion_vec, axis=1)      if epoch_id == 0:         min_point = np.min(cloud_x, axis=0)         local_origin = np.floor(min_point / 100) * 100          # array to dataframe     df_y = pd.DataFrame(cloud_y, columns=[\"X\", \"Y\", \"Z\"])     df_new = pd.DataFrame(cloud_new, columns=[\"X\", \"Y\", \"Z\"])      vapc_y = vapc.Vapc(voxel_size=voxel_size, origin=local_origin.tolist())     vapc_y.df = df_y     vapc_y.compute = [\"center_of_voxel\"]     vapc_y.compute_requested_attributes()      vapc_new = vapc.Vapc(voxel_size=voxel_size, origin=local_origin.tolist())     vapc_new.df = df_new     vapc_new.compute = [\"center_of_voxel\"]     vapc_new.compute_requested_attributes()          if epoch_id == 0:         seed_points = np.array((vapc_new.df[\"center_x\"].values, vapc_new.df[\"center_y\"].values, vapc_new.df[\"center_z\"].values)).T         seed_points = np.unique(seed_points, axis=0)     else:         seed_points = pts_y_original          # get nearest neighbours to seed points in cloud_new     tree_ynew = KDTree(cloud_new)      dist, idx_yn = tree_ynew.query(seed_points, k=1)      # get points     pts_y_original = cloud_y[idx_yn, :]     pts_y_new = cloud_new[idx_yn, :]      # create lines from nearest points to seed in cloud y and corresponding points in cloud x     lines = np.hstack((pts_y_original, pts_y_new))      # create json object for each line     for i in range(lines.shape[0]):         geoObject = {}         geoObject[\"id\"] = f\"{epoch_id}{i:04d}\"         geoObject[\"type\"] = \"motion_vector\"         geoObject[\"dateTime\"] = t_min         geoObject[\"geometry\"] = {             \"type\": \"\",             \"coordinates\": [                 lines[i, 0:3].tolist(),                 lines[i, 3:6].tolist()             ]         }         geoObject[\"customAttributes\"] = {             \"motion_magnitudes\": motion_magnitudes[i],             \"epoch_id\": epoch_id         }                  geoObjects.append(geoObject)      observations[\"observations\"].append({         \"startDateTime\": t_min,         \"endDateTime\": t_max,         \"geoObjects\": geoObjects,         \"backgroundImageData\": {             \"url\": list_background_projections[epoch_id].bg_image_filename[0],             \"height\": Image.open(images[epoch_id]).convert(\"RGB\").size[1],             \"width\": Image.open(images[epoch_id]).convert(\"RGB\").size[0]         },     }) In\u00a0[13]: Copied! <pre>list_observation_projection = []\nfor epoch_id, observation in enumerate(observations['observations']):\n    background_projection = list_background_projections[epoch_id]\n\n    observation_projection = projection.ProjectChange(observation=observation,\n                            project_name=f\"{project_name}_{epoch_id}_{epoch_id+1}\",\n                            projected_image_path=background_projection.bg_image_filename[0],\n                            projected_events_folder=output_folder,\n                            epsg=None)\n\n    observation_projection.project_change()\n    list_observation_projection.append(observation_projection)\n</pre> list_observation_projection = [] for epoch_id, observation in enumerate(observations['observations']):     background_projection = list_background_projections[epoch_id]      observation_projection = projection.ProjectChange(observation=observation,                             project_name=f\"{project_name}_{epoch_id}_{epoch_id+1}\",                             projected_image_path=background_projection.bg_image_filename[0],                             projected_events_folder=output_folder,                             epsg=None)      observation_projection.project_change()     list_observation_projection.append(observation_projection) <p>Let's display the branch (projected image) and the motion vectors in another GIF.</p> In\u00a0[14]: Copied! <pre>branch_crop_box = (130, 1170, 1600, 2000) # (left, upper, right, lower)\nframes = []\ngif_path = \"../docs/img/tree_projections_plus_observations.gif\"\nfont = ImageFont.load_default(size = 50)\n\nfor enum, img in enumerate(images):\n    frm = Image.open(img).convert(\"RGB\")\n    frm = frm.crop(branch_crop_box)\n    draw = ImageDraw.Draw(frm)\n    draw.text((50, 50), f\"Epoch: {enum}\", fill=(255, 255, 255), font=font)\n\n    observation_projection = list_observation_projection[enum]\n\n    # Load geojson\n    with open(observation_projection.geojson_name, 'r') as f:\n        geojson_data = json.load(f)\n\n    for feature in geojson_data[\"features\"]:\n        geom = shape(feature[\"geometry\"])\n        coords = [(int(x) - branch_crop_box[0], -int(y) - branch_crop_box[1]) for x, y in geom.coords]\n        draw.line(coords, fill=\"yellow\", width=2)\n\n    frames.append(frm)\n    \n\nframes[0].save(\n    gif_path,\n    save_all=True,\n    append_images=frames[1:],\n    duration=600,\n    loop=0\n)\n</pre> branch_crop_box = (130, 1170, 1600, 2000) # (left, upper, right, lower) frames = [] gif_path = \"../docs/img/tree_projections_plus_observations.gif\" font = ImageFont.load_default(size = 50)  for enum, img in enumerate(images):     frm = Image.open(img).convert(\"RGB\")     frm = frm.crop(branch_crop_box)     draw = ImageDraw.Draw(frm)     draw.text((50, 50), f\"Epoch: {enum}\", fill=(255, 255, 255), font=font)      observation_projection = list_observation_projection[enum]      # Load geojson     with open(observation_projection.geojson_name, 'r') as f:         geojson_data = json.load(f)      for feature in geojson_data[\"features\"]:         geom = shape(feature[\"geometry\"])         coords = [(int(x) - branch_crop_box[0], -int(y) - branch_crop_box[1]) for x, y in geom.coords]         draw.line(coords, fill=\"yellow\", width=2)      frames.append(frm)       frames[0].save(     gif_path,     save_all=True,     append_images=frames[1:],     duration=600,     loop=0 ) In\u00a0[15]: Copied! <pre>aggregated_data = utilities.DataModel([])\n\nfor (i, observation_projection) in enumerate(list_observation_projection):\n    if observation_projection is None:\n        continue\n    elif observation_projection.observation[\"geoObjects\"] is None:\n        img_size = Image.open(png_images[i]).convert(\"RGB\").size\n        aggregated_data.observations.append(utilities.Observation(\n            startDateTime=observation_projection.observation[\"startDateTime\"],\n            endDateTime=observation_projection.observation[\"endDateTime\"],\n            geoObjects=[],\n            backgroundImageData=utilities.ImageData(\n                url=str(\"http://localhost:8001/\" + png_images[i]).replace(\"\\\\\", \"/\"),\n                width=img_size[0],\n                height=img_size[1]\n            )\n        ))\n        continue\n    \n    with open(observation_projection.geojson_name, 'r') as f:\n        geojson_data = json.load(f)\n    \n    img_size = Image.open(png_images[i]).convert(\"RGB\").size\n    geometry = geojson_data.get(\"features\")[0].get(\"geometry\")\n    coords = geometry.get(\"coordinates\")\n    new_observations = utilities.convert_geojson_to_datamodel(\n        geojson=geojson_data,\n        bg_img=str(\"http://localhost:8001/\" + png_images[i]).replace(\"\\\\\", \"/\"),\n        width=img_size[0],\n        height=img_size[1]\n    )\n\n    aggregated_data.observations.extend(new_observations.observations)\n\nwith open(f\"{output_folder}/final_data_model.json\", \"w\") as f:\n    f.write(aggregated_data.toJSON())\n</pre> aggregated_data = utilities.DataModel([])  for (i, observation_projection) in enumerate(list_observation_projection):     if observation_projection is None:         continue     elif observation_projection.observation[\"geoObjects\"] is None:         img_size = Image.open(png_images[i]).convert(\"RGB\").size         aggregated_data.observations.append(utilities.Observation(             startDateTime=observation_projection.observation[\"startDateTime\"],             endDateTime=observation_projection.observation[\"endDateTime\"],             geoObjects=[],             backgroundImageData=utilities.ImageData(                 url=str(\"http://localhost:8001/\" + png_images[i]).replace(\"\\\\\", \"/\"),                 width=img_size[0],                 height=img_size[1]             )         ))         continue          with open(observation_projection.geojson_name, 'r') as f:         geojson_data = json.load(f)          img_size = Image.open(png_images[i]).convert(\"RGB\").size     geometry = geojson_data.get(\"features\")[0].get(\"geometry\")     coords = geometry.get(\"coordinates\")     new_observations = utilities.convert_geojson_to_datamodel(         geojson=geojson_data,         bg_img=str(\"http://localhost:8001/\" + png_images[i]).replace(\"\\\\\", \"/\"),         width=img_size[0],         height=img_size[1]     )      aggregated_data.observations.extend(new_observations.observations)  with open(f\"{output_folder}/final_data_model.json\", \"w\") as f:     f.write(aggregated_data.toJSON())"},{"location":"branch_evolution.html#branch-evolution","title":"Branch evolution\u00b6","text":"<p>Notebook contributors: William Albert, Hannah Weiser, July 2025</p> <p>This notebook demonstrates the preparation of the 4DGeo branch evolution example. The dataset contains weekly LiDAR scans of a tree over a time period of 6 weeks, with the first scan on 27 March 2025 and the last scan on 9 May 2025.</p> <p>The starting point of the notebook are pointwise motion vectors computed for all pairs of consecutive scans. These may be computed using tools like PlantMove. Here, we read these motion vectors from a .npz file with Python. In addition, we have .laz files for the individual scans, which for each epoch are split into the branch of interest and the rest of the tree.</p>"},{"location":"branch_evolution.html#imports","title":"Imports\u00b6","text":""},{"location":"branch_evolution.html#get-the-data","title":"Get the data\u00b6","text":""},{"location":"branch_evolution.html#overview-of-the-data","title":"Overview of the data\u00b6","text":"<p>Let's first get an overview of the input data. We visualize the point clouds of the first and last scan side by side with <code>matplotlib</code> by height, showing the branch of interest in black.</p>"},{"location":"branch_evolution.html#projections-point-cloud","title":"Projections (point cloud)\u00b6","text":"<p>For each observation, we create a 2D image of the point cloud by projecting the 3D points onto a 2D plane from the viewpoint of the scanner. Before that, we need to prepare the data accordingly.</p>"},{"location":"branch_evolution.html#prepare-the-configuration-file","title":"Prepare the configuration file\u00b6","text":""},{"location":"branch_evolution.html#merge-each-branch-with-its-respective-tree","title":"Merge each branch with its respective tree\u00b6","text":"<p>In our input data, point clouds of the branch of interest are separated from the rest of the tree. For each epoch, we merge</p> <ol> <li>The branch point cloud of the epoch (coloured in red),</li> <li>The branch point cloud of the next epoch (coloured in blue)</li> <li>The point cloud of the remaining tree at the epoch (coloured in grayscale by intensity)</li> </ol>"},{"location":"branch_evolution.html#project-the-point-clouds-onto-2d-images","title":"Project the point clouds onto 2D images\u00b6","text":"<p>We now generate the background images. For this, we are using classes and functions from the <code>fourdgeo</code> library. The class <code>PCloudProjection</code> directly takes our configuration file as input and writes the generated images to our specific <code>output_folder</code>.</p>"},{"location":"branch_evolution.html#convert-tif-images-to-png-images","title":"Convert .tif Images to .png Images\u00b6","text":"<p>Because the dashboard (currently) does not support TIF files, we need to convert the generated background images to the PNG format.</p>"},{"location":"branch_evolution.html#projections-motion-vectors","title":"Projections (motion vectors)\u00b6","text":""},{"location":"branch_evolution.html#derive-a-subset-of-motion-vectors-by-voxelization-and-save-as-geoobject","title":"Derive a subset of motion vectors by voxelization and save as geoObject\u00b6","text":"<p>Since the visualization would be too cluttered with all motion vectors, we reduce the number of motion vectors by voxelizing the point cloud and only keeping one motion vector per voxel. We write this motion vector as a dictionary into a list <code>observations</code>.</p>"},{"location":"branch_evolution.html#project-the-vectors-from-each-observation-onto-their-respective-background-image","title":"Project the vectors from each observation onto their respective background image\u00b6","text":"<p>Finally, we project these motion vectors onto the 2D image plane and save them in GeoJSON files in the <code>output_folder</code>, together with the projected images.</p>"},{"location":"branch_evolution.html#extract-the-final-json","title":"Extract the final JSON\u00b6","text":"<p>In order to include this data into the dashboard, we now need to convert the created geojson data to the dashboard data model. For this, we iterate through all geojson files and create their observation objects and the aggregate them into one final data model object and store it in the <code>output_folder</code>. This files can then be loaded with the 4DGeo Dashboard.</p>"},{"location":"branch_evolution.html#visualise-the-data-in-the-dashboard","title":"Visualise the data in the dashboard\u00b6","text":"<p>To see our results in the actual dashboard, we need to host the created json file to make it accessbile. As a quick and easy solution, we can use the http.server python library. The python script <code>server-host.py</code> hosts all the files in this directory. So in order to setup this local hosting, we need navigate to the <code>4DGeo/docs</code> folder to execute the following command in a commandline:</p> <p><code>python server_host.py</code></p> <p>Lastly, inside of the dashboard, set the data source to <code>http://localhost:8001/out/rockfall_monitoring/final_data_model.json</code>.</p>"},{"location":"getting_started.html","title":"Getting started","text":"In\u00a0[1]: Copied! <pre>import sys\nsys.path.insert(0, \"../src\")\nfrom fourdgeo.helpers.getting_started import *\n</pre> import sys sys.path.insert(0, \"../src\") from fourdgeo.helpers.getting_started import * In\u00a0[2]: Copied! <pre># Load the rockfall data or use your own data by giving the path to the data folder variable\ndata_folder = download_example_data({\n    \"data_url\": \"https://zenodo.org/api/records/16153369/files/rockfall_trier.zip/content\",\n    \"data_hash\": \"77b343183c86cbc3f72e0edbe362cc3219d41e00fcf4389ab650a09a13b1b1ec\",\n    \"file_name\": \"rockfall_trier.zip\",\n    \"data_folder\": \"data/rockfall_trier\",\n})\n</pre> # Load the rockfall data or use your own data by giving the path to the data folder variable data_folder = download_example_data({     \"data_url\": \"https://zenodo.org/api/records/16153369/files/rockfall_trier.zip/content\",     \"data_hash\": \"77b343183c86cbc3f72e0edbe362cc3219d41e00fcf4389ab650a09a13b1b1ec\",     \"file_name\": \"rockfall_trier.zip\",     \"data_folder\": \"data/rockfall_trier\", }) In\u00a0[3]: Copied! <pre>configuration = get_example_configuration()\n</pre> configuration = get_example_configuration() In\u00a0[\u00a0]: Copied! <pre>list_background_projections = convert_point_cloud_time_series_to_datamodel(data_folder, configuration)\n</pre> list_background_projections = convert_point_cloud_time_series_to_datamodel(data_folder, configuration) In\u00a0[\u00a0]: Copied! <pre>host_data(configuration)\n</pre> host_data(configuration) In\u00a0[\u00a0]: Copied! <pre>import sys\nsys.path.insert(0, \"../src\")\nfrom fourdgeo.helpers.getting_started import *\n\ndata_folder = download_example_data()\n\nconfiguration = get_example_configuration()\n\nlist_background_projections = convert_point_cloud_time_series_to_datamodel(data_folder, configuration)\n\nhost_data(configuration)\n</pre> import sys sys.path.insert(0, \"../src\") from fourdgeo.helpers.getting_started import *  data_folder = download_example_data()  configuration = get_example_configuration()  list_background_projections = convert_point_cloud_time_series_to_datamodel(data_folder, configuration)  host_data(configuration)"},{"location":"getting_started.html#easy-monitoring-example","title":"Easy monitoring example\u00b6","text":"<p>Notebook contributors: Ronald Tabernig, William Albert, July 2025</p> <p>This notebook demonstrates the data preparation. The dataset contains 6 scans of a rockfall area in Trier, Germany captured hourly in the night from 25 August 2024 to 26 August 2024. We've prepared the needed functionality in the helper functions.</p> <p>To make this work with your own list of point clouds, you simply need to adjust the url and paths when downloading. And make sure the name and timestamp of each file is matching the format defined in the configuration.</p>"},{"location":"getting_started.html#imports","title":"Imports\u00b6","text":""},{"location":"getting_started.html#get-the-data","title":"Get the data\u00b6","text":""},{"location":"getting_started.html#projections","title":"Projections\u00b6","text":""},{"location":"getting_started.html#prepare-the-configuration-file","title":"Prepare the configuration file\u00b6","text":"<p>We use a configuration dictionary that contains general project settings like the <code>output_folder</code> and the relevant settings for the point cloud projection. For the projection, parameters like the <code>camera_position</code> and the <code>resolution_cm</code> are essential.</p>"},{"location":"getting_started.html#generate-and-populate-the-data-model-with-the-input-point-clouds","title":"Generate and populate the data model with the input point clouds\u00b6","text":"<p>The final json file is now finished and stored.</p>"},{"location":"getting_started.html#visualise-the-data-in-the-dashboard","title":"Visualise the data in the dashboard\u00b6","text":"<p>To see your results in the actual dashboard, we need to host the created json file and images to make them accessbile. As a quick and easy solution, we can use the http.server python library. Running the following cell will host your newly converted data and make it available for a dashboard to read it.</p> <p>For example, this dashboard reads that data and visualises your images! (This link only works if you didn't change the port number in the configuration)</p> <p>If you want to create your own dashboard, simply set the data source to <code>http://localhost:PORT_NUMBER/out/getting_started/data_model.json</code>.</p>"},{"location":"getting_started.html#putting-it-all-together","title":"Putting it all together\u00b6","text":"<p>Heres every step in one so you can copy and paste it into your own environment! Remember to also copy the helper functions.</p>"},{"location":"rockfall_monitoring.html","title":"Rockfall monitoring","text":"<p>Related publications:</p> <ul> <li>Czerwonka-Schr\u00f6der, D., Schulte, F., Albert, W., Hosseini, K., Tabernig, R., Yang, Y., H\u00f6fle, B., Holst, C. &amp; Zimmermann, K. (2025): AImon5.0: Echtzeit\u00fcberwachung gravitativer Massenbewegungen \u2013 Eine Fallstudie am Trierer Augenscheiner. 23. Internationale Geod\u00e4tische Woche, 23, 1-13. https://doi.org/10.11588/heidok.00036222</li> <li>Tabernig, R., Albert, W., Weiser, H., Fritzmann, P., Anders, K., Rutzinger, M., &amp; H\u00f6fle, B. (2025). Temporal aggregation of point clouds improves permanent laser scanning of landslides in forested areas. Science of Remote Sensing, 12, 100254. https://doi.org/10.1016/j.srs.2025.100254</li> </ul> In\u00a0[1]: Copied! <pre>import py4dgeo\nimport laspy\nimport numpy as np\nimport os\nimport sys\nimport json\nsys.path.insert(0, \"../src\")\nfrom fourdgeo import projection\nfrom fourdgeo import utilities\nfrom fourdgeo import change\n\n# File download and handling\nfrom pathlib import Path\nimport pooch\nfrom tqdm import tqdm\n\n# Image handling\nfrom PIL import Image, ImageDraw, ImageFont, ImageSequence\nfrom IPython.display import HTML\n</pre> import py4dgeo import laspy import numpy as np import os import sys import json sys.path.insert(0, \"../src\") from fourdgeo import projection from fourdgeo import utilities from fourdgeo import change  # File download and handling from pathlib import Path import pooch from tqdm import tqdm  # Image handling from PIL import Image, ImageDraw, ImageFont, ImageSequence from IPython.display import HTML In\u00a0[2]: Copied! <pre># Handle file download/reading here\ndata_url = \"https://zenodo.org/api/records/16153369/files/rockfall_trier.zip/content\"\ndata_hash = \"77b343183c86cbc3f72e0edbe362cc3219d41e00fcf4389ab650a09a13b1b1ec\"\nfile_name = \"rockfall_trier.zip\"\ndata_folder = \"data/rockfall_trier\"\n\nif not Path(data_folder).exists():\n    fnames = pooch.retrieve(url=data_url,\n                            known_hash=data_hash,\n                            path=\"./\",\n                            fname=file_name,\n                            processor=pooch.Unzip(extract_dir=data_folder),\n                            progressbar=True)\n    os.remove(file_name)\n</pre> # Handle file download/reading here data_url = \"https://zenodo.org/api/records/16153369/files/rockfall_trier.zip/content\" data_hash = \"77b343183c86cbc3f72e0edbe362cc3219d41e00fcf4389ab650a09a13b1b1ec\" file_name = \"rockfall_trier.zip\" data_folder = \"data/rockfall_trier\"  if not Path(data_folder).exists():     fnames = pooch.retrieve(url=data_url,                             known_hash=data_hash,                             path=\"./\",                             fname=file_name,                             processor=pooch.Unzip(extract_dir=data_folder),                             progressbar=True)     os.remove(file_name) <p>Here, we perform change analysis between consecutive pairs of epochs, i.e., between the first and the second, the second and the third, and so on. We compute point cloud distances using the M3C2 algorithm (Lague et al. 2013) as implemented in py4dgeo, mask only significant changes, cluster the masked points using DBSCAN and finally extract change objects, which are defined by a polygon outline, attributes such as the mean M3C2 magnitude and the size, as well as a timestamp.</p> In\u00a0[3]: Copied! <pre>m3c2_settings = {\"cyl_radius\":1,\n                 \"normal_radii\":[1.0,],\n                 \"max_distance\": 10.0,\n                 \"registration_error\":0.025\n                 }\n\n# DBScan parameters\ndbscan_eps = 1\nmin_cluster_size = 100\n</pre> m3c2_settings = {\"cyl_radius\":1,                  \"normal_radii\":[1.0,],                  \"max_distance\": 10.0,                  \"registration_error\":0.025                  }  # DBScan parameters dbscan_eps = 1 min_cluster_size = 100 In\u00a0[\u00a0]: Copied! <pre>observations = {\"observations\": []}\n\n# Gather &amp; sort only the .laz files\nlaz_paths = list(Path(data_folder).glob(\"*.laz\"))\nlaz_paths = sorted(laz_paths)\n\n# Walk through each consecutive pair\nfor prev_path, curr_path in zip(laz_paths, laz_paths[1:]):\n    prev_fname = os.path.basename(prev_path)\n    curr_fname = os.path.basename(curr_path)\n\n    startDateTime = utilities.iso_timestamp(prev_fname) + \"Z\"\n    endDateTime   = utilities.iso_timestamp(curr_fname) + \"Z\"\n\n    # Load point clouds\n    epoch_0 = py4dgeo.read_from_las(prev_path.resolve())  # make absolute, so py4dgeo does not download and check if the file is in py4dgeo-test-data\n    epoch_1 = py4dgeo.read_from_las(curr_path.resolve())\n\n    # Compute M3C2\n    m3c2 = py4dgeo.M3C2(\n        epochs=(epoch_0, epoch_1),\n        corepoints=epoch_0.cloud,\n        cyl_radius=m3c2_settings[\"cyl_radius\"],\n        normal_radii=m3c2_settings[\"normal_radii\"],\n        max_distance=m3c2_settings[\"max_distance\"],\n        registration_error=m3c2_settings[\"registration_error\"],\n    )\n    distances, uncertainties = m3c2.run()\n\n    # Mask &amp; stack only significant changes\n    mask = np.abs(distances) &gt;= uncertainties[\"lodetection\"]\n    if not mask.any():\n        print(f\"No significant changes between {prev_fname} \u2192 {curr_fname}\")\n        continue\n\n    significant_pts = epoch_0.cloud[mask]\n    significant_d  = distances[mask]\n    changes = np.column_stack((significant_pts, significant_d))\n\n    # Cluster &amp; extract geoObjects\n    labeled = change.cluster_m3c2_changes(changes, dbscan_eps, min_cluster_size)\n    geoObjects = change.extract_geoObjects_from_clusters(labeled, endDateTime, prev_fname, curr_fname)\n\n    observations[\"observations\"].append({\n        \"backgroundImageData\": {},\n        \"startDateTime\": startDateTime,\n        \"endDateTime\": endDateTime,\n        \"geoObjects\": geoObjects,\n    })\n</pre> observations = {\"observations\": []}  # Gather &amp; sort only the .laz files laz_paths = list(Path(data_folder).glob(\"*.laz\")) laz_paths = sorted(laz_paths)  # Walk through each consecutive pair for prev_path, curr_path in zip(laz_paths, laz_paths[1:]):     prev_fname = os.path.basename(prev_path)     curr_fname = os.path.basename(curr_path)      startDateTime = utilities.iso_timestamp(prev_fname) + \"Z\"     endDateTime   = utilities.iso_timestamp(curr_fname) + \"Z\"      # Load point clouds     epoch_0 = py4dgeo.read_from_las(prev_path.resolve())  # make absolute, so py4dgeo does not download and check if the file is in py4dgeo-test-data     epoch_1 = py4dgeo.read_from_las(curr_path.resolve())      # Compute M3C2     m3c2 = py4dgeo.M3C2(         epochs=(epoch_0, epoch_1),         corepoints=epoch_0.cloud,         cyl_radius=m3c2_settings[\"cyl_radius\"],         normal_radii=m3c2_settings[\"normal_radii\"],         max_distance=m3c2_settings[\"max_distance\"],         registration_error=m3c2_settings[\"registration_error\"],     )     distances, uncertainties = m3c2.run()      # Mask &amp; stack only significant changes     mask = np.abs(distances) &gt;= uncertainties[\"lodetection\"]     if not mask.any():         print(f\"No significant changes between {prev_fname} \u2192 {curr_fname}\")         continue      significant_pts = epoch_0.cloud[mask]     significant_d  = distances[mask]     changes = np.column_stack((significant_pts, significant_d))      # Cluster &amp; extract geoObjects     labeled = change.cluster_m3c2_changes(changes, dbscan_eps, min_cluster_size)     geoObjects = change.extract_geoObjects_from_clusters(labeled, endDateTime, prev_fname, curr_fname)      observations[\"observations\"].append({         \"backgroundImageData\": {},         \"startDateTime\": startDateTime,         \"endDateTime\": endDateTime,         \"geoObjects\": geoObjects,     }) <p>Let's have a look at what a change <code>geoObject</code> contains:</p> In\u00a0[5]: Copied! <pre>observations[\"observations\"][2][\"geoObjects\"][0]\n</pre> observations[\"observations\"][2][\"geoObjects\"][0] Out[5]: <pre>{'id': '096c5b5106264abb891be775a61dd656',\n 'type': 'unknown',\n 'dateTime': '2024-08-26T01:00:06Z',\n 'geometry': {'type': 'Polygon',\n  'coordinates': [[-258.019, 158.27100000000002, 5.363],\n   [-258.015, 158.19400000000002, 5.831],\n   [-258.005, 158.187, 5.751],\n   [-258.005, 158.18800000000002, 5.672],\n   [-258.397, 158.428, 5.36],\n   [-258.177, 158.293, 5.04],\n   [-258.129, 158.151, 5.9510000000000005],\n   [-258.677, 158.487, 5.244],\n   [-258.25100000000003, 158.225, 5.156],\n   [-258.298, 158.255, 5.0],\n   [-258.615, 158.356, 6.099],\n   [-258.32, 158.17600000000002, 6.009],\n   [-259.543, 158.731, 5.434],\n   [-259.471, 158.687, 5.272],\n   [-259.38, 158.52700000000002, 6.253],\n   [-259.473, 158.584, 6.098],\n   [-259.046, 158.323, 4.811],\n   [-258.974, 158.214, 4.847],\n   [-260.13100000000003, 158.64000000000001, 5.308],\n   [-259.866, 158.478, 5.15],\n   [-260.162, 158.534, 6.9750000000000005],\n   [-260.031, 158.454, 6.892],\n   [-259.777, 158.3, 5.12],\n   [-260.225, 158.491, 7.009],\n   [-260.595, 158.431, 6.273],\n   [-260.55400000000003, 158.406, 6.111],\n   [-260.559, 158.409, 6.027],\n   [-260.64300000000003, 158.46, 5.547],\n   [-261.731, 158.92000000000002, 6.343],\n   [-261.337, 158.681, 5.849],\n   [-261.803, 158.873, 6.354],\n   [-261.598, 158.673, 7.025],\n   [-261.765, 158.775, 6.625],\n   [-261.791, 158.793, 6.465],\n   [-261.66700000000003, 158.607, 6.676]]},\n 'customAttributes': {'X_centroid': np.float64(-259.8313391304348),\n  'Y_centroid': np.float64(158.48924782608697),\n  'Z_centroid': np.float64(5.991530434782609),\n  'm3c2_magnitude_abs_average_per_cluster': np.float64(1.0733661294671384),\n  'volume': 1.2427361073333316,\n  'surface_area': 11.436782819482161,\n  'surface_to_volume_ratio': 9.20290538916042,\n  'cluster_size_points': 230}}</pre> In\u00a0[6]: Copied! <pre>configuration = {\n    \"project_setting\": {\n        \"project_name\": \"Rockfall_monitoring\",\n        \"output_folder\": \"./out/rockfall_monitoring\",\n        \"temporal_format\": \"%y%m%d_%H%M%S\",\n        \"silent_mode\": True,\n        \"include_timestamp\": False\n    },\n    \"pc_projection\": {\n        \"pc_path\": \"\",\n        \"make_range_image\": True,\n        \"make_color_image\": False,\n        \"top_view\": False,\n        \"save_rot_pc\": False,\n        \"resolution_cm\": 12.5,\n        \"camera_position\": [\n            0.0,\n            0.0,\n            0.0\n        ],\n        \"rgb_light_intensity\": 100,\n        \"range_light_intensity\": 10,\n        \"epsg\": None\n    }\n}\n</pre> configuration = {     \"project_setting\": {         \"project_name\": \"Rockfall_monitoring\",         \"output_folder\": \"./out/rockfall_monitoring\",         \"temporal_format\": \"%y%m%d_%H%M%S\",         \"silent_mode\": True,         \"include_timestamp\": False     },     \"pc_projection\": {         \"pc_path\": \"\",         \"make_range_image\": True,         \"make_color_image\": False,         \"top_view\": False,         \"save_rot_pc\": False,         \"resolution_cm\": 12.5,         \"camera_position\": [             0.0,             0.0,             0.0         ],         \"rgb_light_intensity\": 100,         \"range_light_intensity\": 10,         \"epsg\": None     } } In\u00a0[7]: Copied! <pre>images = []\nlist_background_projections = []\npcs = sorted(laz_paths)\n\nfor enum, pc in enumerate(pcs):\n    lf = laspy.read(pc)\n    configuration['pc_projection']['pc_path'] = pc\n    project_name = configuration['project_setting']['project_name']\n    output_folder = configuration['project_setting']['output_folder']\n\n    background_projection = projection.PCloudProjection(\n        configuration = configuration,\n        project_name = project_name,\n        projected_image_folder = output_folder,\n    )\n    # First projection\n    if enum == 0:\n        (\n            ref_h_fov, ref_v_fov, ref_anchor_point_xyz, \n            ref_h_img_res, ref_v_img_res\n        ) = background_projection.project_pc(buffer_m = 0.5)\n    # Next projections using reference data\n    else:\n        background_projection.project_pc(\n            ref_theta=ref_h_fov[0],\n            ref_phi=ref_v_fov[0],\n            ref_anchor_point_xyz=None,\n            ref_h_fov=ref_h_fov,\n            ref_v_fov=ref_v_fov,\n            ref_h_img_res=ref_h_img_res,\n            ref_v_img_res=ref_v_img_res\n        )\n\n    bg_img = background_projection.bg_image_filename[0]\n    if bg_img[0] == \".\":\n        bg_img = bg_img[2:]\n\n    outfile = bg_img.split('.')[0] + f\"_{enum}_{enum+1}.\" + bg_img.split('.')[1]\n\n    try:\n        os.rename(bg_img, outfile)\n    except FileExistsError:\n        os.remove(outfile)\n        os.rename(bg_img, outfile)\n\n    images.append(outfile)\n\n    background_projection.bg_image_filename[0] = outfile\n    list_background_projections.append(background_projection)\n</pre> images = [] list_background_projections = [] pcs = sorted(laz_paths)  for enum, pc in enumerate(pcs):     lf = laspy.read(pc)     configuration['pc_projection']['pc_path'] = pc     project_name = configuration['project_setting']['project_name']     output_folder = configuration['project_setting']['output_folder']      background_projection = projection.PCloudProjection(         configuration = configuration,         project_name = project_name,         projected_image_folder = output_folder,     )     # First projection     if enum == 0:         (             ref_h_fov, ref_v_fov, ref_anchor_point_xyz,              ref_h_img_res, ref_v_img_res         ) = background_projection.project_pc(buffer_m = 0.5)     # Next projections using reference data     else:         background_projection.project_pc(             ref_theta=ref_h_fov[0],             ref_phi=ref_v_fov[0],             ref_anchor_point_xyz=None,             ref_h_fov=ref_h_fov,             ref_v_fov=ref_v_fov,             ref_h_img_res=ref_h_img_res,             ref_v_img_res=ref_v_img_res         )      bg_img = background_projection.bg_image_filename[0]     if bg_img[0] == \".\":         bg_img = bg_img[2:]      outfile = bg_img.split('.')[0] + f\"_{enum}_{enum+1}.\" + bg_img.split('.')[1]      try:         os.rename(bg_img, outfile)     except FileExistsError:         os.remove(outfile)         os.rename(bg_img, outfile)      images.append(outfile)      background_projection.bg_image_filename[0] = outfile     list_background_projections.append(background_projection) In\u00a0[8]: Copied! <pre>png_images = []\n\nfor background_projection in list_background_projections:\n    image_path = background_projection.bg_image_filename[0]\n    filename = str.split(image_path, \".\")[0]\n    try:\n        with Image.open(image_path) as im:\n            for i, page in enumerate(ImageSequence.Iterator(im)):\n                out_path = filename + \".png\"\n                if not os.path.isfile(out_path):\n                    try:\n                        page.save(out_path)\n                    except:\n                        print(out_path)\n            png_images.append(out_path)\n    except:\n        print(filename)\n</pre> png_images = []  for background_projection in list_background_projections:     image_path = background_projection.bg_image_filename[0]     filename = str.split(image_path, \".\")[0]     try:         with Image.open(image_path) as im:             for i, page in enumerate(ImageSequence.Iterator(im)):                 out_path = filename + \".png\"                 if not os.path.isfile(out_path):                     try:                         page.save(out_path)                     except:                         print(out_path)             png_images.append(out_path)     except:         print(filename) In\u00a0[9]: Copied! <pre>project_name = configuration[\"project_setting\"][\"project_name\"]\nlist_observation_projection = []\n\nfor epoch_id, observation in enumerate(observations['observations']):\n    background_projection = list_background_projections[epoch_id]\n    observation_projection = projection.ProjectChange(observation=observation,\n                            project_name=f\"{project_name}_{epoch_id}_{epoch_id+1}\",\n                            projected_image_path=background_projection.bg_image_filename[0],\n                            projected_events_folder=output_folder,\n                            epsg=None)\n\n    if observation[\"geoObjects\"] is not None:\n        observation_projection.project_change()\n    list_observation_projection.append(observation_projection)\n</pre> project_name = configuration[\"project_setting\"][\"project_name\"] list_observation_projection = []  for epoch_id, observation in enumerate(observations['observations']):     background_projection = list_background_projections[epoch_id]     observation_projection = projection.ProjectChange(observation=observation,                             project_name=f\"{project_name}_{epoch_id}_{epoch_id+1}\",                             projected_image_path=background_projection.bg_image_filename[0],                             projected_events_folder=output_folder,                             epsg=None)      if observation[\"geoObjects\"] is not None:         observation_projection.project_change()     list_observation_projection.append(observation_projection) In\u00a0[10]: Copied! <pre>frames = []\ngif_path = \"../docs/img/rockfall_projections_plus_observations.gif\"\nfont = ImageFont.load_default(size = 30)\n\nfor enum, img in enumerate(images[1:]):\n    frm = Image.open(img).convert(\"RGB\")\n    draw = ImageDraw.Draw(frm)\n    draw.text((500, 36), f\"Epoch: {enum}\", fill=(255, 255, 255), font=font)\n\n    observation_projection = list_observation_projection[enum]\n\n    # Load geojson\n    if observation_projection.observation[\"geoObjects\"] is not None:\n        with open(observation_projection.geojson_name, 'r') as f:\n            geojson_data = json.load(f)\n\n        for feature in geojson_data[\"features\"]:\n            coords = np.array(feature[\"geometry\"]['coordinates'][0])\n            coords[:,1] *= -1\n            coords = coords.reshape(len(coords)*2)\n            draw.polygon(list(coords), outline='yellow', width=4)\n\n    frames.append(frm)\n    \n\nframes[0].save(\n    gif_path,\n    save_all=True,\n    append_images=frames[1:],\n    duration=1000,\n    loop=0\n)\n</pre> frames = [] gif_path = \"../docs/img/rockfall_projections_plus_observations.gif\" font = ImageFont.load_default(size = 30)  for enum, img in enumerate(images[1:]):     frm = Image.open(img).convert(\"RGB\")     draw = ImageDraw.Draw(frm)     draw.text((500, 36), f\"Epoch: {enum}\", fill=(255, 255, 255), font=font)      observation_projection = list_observation_projection[enum]      # Load geojson     if observation_projection.observation[\"geoObjects\"] is not None:         with open(observation_projection.geojson_name, 'r') as f:             geojson_data = json.load(f)          for feature in geojson_data[\"features\"]:             coords = np.array(feature[\"geometry\"]['coordinates'][0])             coords[:,1] *= -1             coords = coords.reshape(len(coords)*2)             draw.polygon(list(coords), outline='yellow', width=4)      frames.append(frm)       frames[0].save(     gif_path,     save_all=True,     append_images=frames[1:],     duration=1000,     loop=0 ) In\u00a0[11]: Copied! <pre>aggregated_data = utilities.DataModel([])\n\nfor (i, observation_projection) in enumerate(list_observation_projection):\n    if observation_projection is None:\n        continue\n    elif observation_projection.observation[\"geoObjects\"] is None:\n        img_size = Image.open(png_images[i + 1]).convert(\"RGB\").size\n        aggregated_data.observations.append(utilities.Observation(\n            startDateTime=observation_projection.observation[\"startDateTime\"],\n            endDateTime=observation_projection.observation[\"endDateTime\"],\n            geoObjects=[],\n            backgroundImageData=utilities.ImageData(\n                url=str(\"http://localhost:8001/\" + png_images[i + 1]).replace(\"\\\\\", \"/\"),\n                width=img_size[0],\n                height=img_size[1]\n            )\n        ))\n        continue\n    \n    with open(observation_projection.geojson_name, 'r') as f:\n        geojson_data = json.load(f)\n    \n    img_size = Image.open(png_images[i + 1]).convert(\"RGB\").size\n    geometry = geojson_data.get(\"features\")[0].get(\"geometry\")\n    coords = geometry.get(\"coordinates\")\n    new_observations = utilities.convert_geojson_to_datamodel(\n        geojson=geojson_data,\n        bg_img=str(\"http://localhost:8001/\" + png_images[i + 1]).replace(\"\\\\\", \"/\"),\n        width=img_size[0],\n        height=img_size[1]\n    )\n\n    aggregated_data.observations.extend(new_observations.observations)\n\nwith open(f\"{output_folder}/final_data_model.json\", \"w\") as f:\n    f.write(aggregated_data.toJSON())\n</pre> aggregated_data = utilities.DataModel([])  for (i, observation_projection) in enumerate(list_observation_projection):     if observation_projection is None:         continue     elif observation_projection.observation[\"geoObjects\"] is None:         img_size = Image.open(png_images[i + 1]).convert(\"RGB\").size         aggregated_data.observations.append(utilities.Observation(             startDateTime=observation_projection.observation[\"startDateTime\"],             endDateTime=observation_projection.observation[\"endDateTime\"],             geoObjects=[],             backgroundImageData=utilities.ImageData(                 url=str(\"http://localhost:8001/\" + png_images[i + 1]).replace(\"\\\\\", \"/\"),                 width=img_size[0],                 height=img_size[1]             )         ))         continue          with open(observation_projection.geojson_name, 'r') as f:         geojson_data = json.load(f)          img_size = Image.open(png_images[i + 1]).convert(\"RGB\").size     geometry = geojson_data.get(\"features\")[0].get(\"geometry\")     coords = geometry.get(\"coordinates\")     new_observations = utilities.convert_geojson_to_datamodel(         geojson=geojson_data,         bg_img=str(\"http://localhost:8001/\" + png_images[i + 1]).replace(\"\\\\\", \"/\"),         width=img_size[0],         height=img_size[1]     )      aggregated_data.observations.extend(new_observations.observations)  with open(f\"{output_folder}/final_data_model.json\", \"w\") as f:     f.write(aggregated_data.toJSON())"},{"location":"rockfall_monitoring.html#rockfall-monitoring","title":"Rockfall monitoring\u00b6","text":"<p>Notebook contributors: Ronald Tabernig, William Albert, Hannah Weiser, July 2025</p> <p>This notebook demonstrates the preparation of a rockfall monitoring example, including a change detection workflow using py4dgeo. The dataset contains 6 LiDAR scans of a rockfall area in Trier, Germany captured hourly in the night from 25 August 2024 to 26 August 2024.</p>"},{"location":"rockfall_monitoring.html#imports","title":"Imports\u00b6","text":""},{"location":"rockfall_monitoring.html#get-the-data","title":"Get the data\u00b6","text":""},{"location":"rockfall_monitoring.html#change-detection","title":"Change detection\u00b6","text":""},{"location":"rockfall_monitoring.html#projections","title":"Projections\u00b6","text":""},{"location":"rockfall_monitoring.html#prepare-the-configuration-file","title":"Prepare the configuration file\u00b6","text":"<p>We use a configuration dictionary that contains general project settings like the <code>output_folder</code> and the relevant settings for the point cloud projection. For the projection, parameters like the <code>camera_position</code> and the <code>resolution_cm</code> are essential.</p>"},{"location":"rockfall_monitoring.html#generate-the-background-images","title":"Generate the background images\u00b6","text":"<p>We now generate the background images. For this, we are using classes and functions from the <code>fourdgeo</code> library. The class <code>PCloudProjection</code> directly takes our configuration file as input and writes them into our specified <code>output_folder</code>.</p>"},{"location":"rockfall_monitoring.html#convert-tif-images-to-png-images","title":"Convert .tif Images to .png Images\u00b6","text":"<p>Because the dashboard (currently) does not support TIF files, we need to convert the generated background images to the PNG format.</p>"},{"location":"rockfall_monitoring.html#project-the-change-events-onto-the-image-background","title":"Project the change events onto the image background\u00b6","text":"<p>Here, we also project the change events onto the background image using the <code>ProjectChange</code> class. The <code>observation</code> GeoJSON files are written to the <code>output_folder</code>.</p>"},{"location":"rockfall_monitoring.html#display-the-rockfall-event-in-the-study-site-as-soon-as-detected","title":"Display the rockfall event in the study site, as soon as detected\u00b6","text":"<p>We generate a GIF of the time series and display the rockfall event using the polygon outlines as soon as it is detected.</p>"},{"location":"rockfall_monitoring.html#extract-the-final-json","title":"Extract the final JSON\u00b6","text":"<p>In order to include this data into the dashboard, we now need to convert the created geojson data to the dashboard data model. For this, we iterate through all geojson files and create their observation objects and the aggregate them into one final data model object and store it in the <code>output_folder</code>. This files can then be loaded with the 4DGeo Dashboard.</p> <p>Note: The path to the background image files has to be a working url. In this example, we use the temporary hosted localhost, explained in this section. Later this can and should be replaced by an actual server containing the files.</p>"},{"location":"rockfall_monitoring.html#visualise-the-data-in-the-dashboard","title":"Visualise the data in the dashboard\u00b6","text":"<p>To see our results in the actual dashboard, we need to host the created json file to make it accessbile. As a quick and easy solution, we can use the http.server python library. The python script <code>server-host.py</code> hosts all the files in this directory. So in order to setup this local hosting, we need navigate to the <code>4DGeo/docs</code> folder to execute the following command in a commandline:</p> <p><code>python server_host.py</code></p> <p>Lastly, inside of the dashboard, set the data source to <code>http://localhost:8001/out/rockfall_monitoring/final_data_model.json</code>.</p>"},{"location":"server_host.html","title":"Server host","text":"In\u00a0[\u00a0]: Copied! <pre># cors_http_server.py\nimport http.server\nimport socketserver\n</pre> # cors_http_server.py import http.server import socketserver In\u00a0[\u00a0]: Copied! <pre>PORT = 8001\n</pre> PORT = 8001 In\u00a0[\u00a0]: Copied! <pre>class CORSRequestHandler(http.server.SimpleHTTPRequestHandler):\n    def end_headers(self):\n        # Add CORS headers\n        self.send_header('Access-Control-Allow-Origin', '*')\n        self.send_header('Access-Control-Allow-Methods', 'GET, OPTIONS')\n        self.send_header('Access-Control-Allow-Headers', '*')\n        http.server.SimpleHTTPRequestHandler.end_headers(self)\n\n    def do_OPTIONS(self):\n      self.send_response(200)\n      self.end_headers()\n</pre> class CORSRequestHandler(http.server.SimpleHTTPRequestHandler):     def end_headers(self):         # Add CORS headers         self.send_header('Access-Control-Allow-Origin', '*')         self.send_header('Access-Control-Allow-Methods', 'GET, OPTIONS')         self.send_header('Access-Control-Allow-Headers', '*')         http.server.SimpleHTTPRequestHandler.end_headers(self)      def do_OPTIONS(self):       self.send_response(200)       self.end_headers() In\u00a0[\u00a0]: Copied! <pre># Start the server\nwith socketserver.TCPServer((\"\", PORT), CORSRequestHandler) as httpd:\n    print(f\"Serving at http://localhost:{PORT}\")\n    httpd.serve_forever()\n</pre> # Start the server with socketserver.TCPServer((\"\", PORT), CORSRequestHandler) as httpd:     print(f\"Serving at http://localhost:{PORT}\")     httpd.serve_forever()"}]}