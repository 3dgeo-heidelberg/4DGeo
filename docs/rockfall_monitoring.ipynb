{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338756d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py4dgeo\n",
    "from sklearn import cluster\n",
    "from scipy import spatial\n",
    "import os\n",
    "import numpy as np\n",
    "import uuid\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Helper to parse timestamp → ISO string\n",
    "def iso_timestamp(fname):\n",
    "    ts = os.path.splitext(fname)[0]  # \"230101_120000\"\n",
    "    return datetime.datetime.strptime(ts, \"%y%m%d_%H%M%S\").isoformat()\n",
    "\n",
    "\n",
    "def cluster_m3c2_changes(significant_changes, dbscan_eps, min_cluster_size):\n",
    "    \"\"\"\n",
    "    Cluster M3C2 changes using DBSCAN and return clusters with their properties.\n",
    "    :param significant_changes: Array of significant changes with shape (n, 4) where n is the number of points.\n",
    "    :param dbscan_eps: The maximum distance between two samples for one to be considered as\n",
    "    :param min_cluster_size: The minimum number of samples in a cluster.\n",
    "    :return: A list of clusters with their properties.\n",
    "    \"\"\"\n",
    "    # DBSCAN clustering\n",
    "    dbscan = cluster.DBSCAN(eps=dbscan_eps, min_samples=min_cluster_size)\n",
    "    labels = dbscan.fit_predict(significant_changes[:, :-1])\n",
    "\n",
    "    # Combine results and check that the labels are unique\n",
    "    all_changes_with_labels = np.column_stack((significant_changes, labels))\n",
    "\n",
    "    # Remove noise points (label -1)\n",
    "    all_changes_with_labels = all_changes_with_labels[all_changes_with_labels[:, -1] != -1]\n",
    "    return all_changes_with_labels\n",
    "\n",
    "def extract_geoObjects_from_clusters(all_changes_with_labels, endDateTime_, filename_0, filename_1):\n",
    "    \"\"\"\n",
    "    Extract observations from clusters of M3C2 changes.\n",
    "    :param all_changes_with_labels: Array of significant changes with labels.\n",
    "    :param endDateTime_: The end date and time of the observation.\n",
    "    :param filename_0: The filename of the first epoch.\n",
    "    :param filename_1: The filename of the second epoch.\n",
    "    :return: A list of observations with geo objects.\n",
    "    \"\"\"\n",
    "    # Extract unique cluster IDs and their counts\n",
    "    cluster_ids, cluster_count = np.unique(all_changes_with_labels[:, -1],return_counts=True)\n",
    "\n",
    "    # If no clusters found, continue to the next file\n",
    "    if len(cluster_ids) == 0:\n",
    "        print(f\"No clusters found between {filename_0} and {filename_1}.\")\n",
    "        return\n",
    "\n",
    "    # backgroundImageData_ = XXX\n",
    "\n",
    "    geoObjects_ = []\n",
    "\n",
    "    # If clusters found, print the largest and smallest cluster sizes    \n",
    "    for cluster_id in range(len(cluster_ids)):\n",
    "        xyz = all_changes_with_labels[all_changes_with_labels[:, -1] == cluster_ids[cluster_id], :3]\n",
    "        m3c2_distances = all_changes_with_labels[all_changes_with_labels[:, -1] == cluster_ids[cluster_id], -2]\n",
    "        convex_hull = spatial.ConvexHull(xyz)\n",
    "        volume = convex_hull.volume\n",
    "        area = convex_hull.area\n",
    "        surface_to_volume_ratio = area / volume if volume > 0 else float('inf')\n",
    "        m3c2_mean_distance = np.mean(np.abs(m3c2_distances))\n",
    "        vertices_of_hull = convex_hull.points[convex_hull.vertices]\n",
    "\n",
    "        # Create an geo object based on the cluster for the observations\n",
    "        dateTime_ = endDateTime_\n",
    "        # Create a unique ID for the cluster\n",
    "        id_ = uuid.uuid4().hex\n",
    "        # Type is \"unknown\", as we don't apply any classifier here\n",
    "        type_ = \"unknown\"\n",
    "\n",
    "        customEntityData_ = {\n",
    "            \"X_centroid\": np.mean(xyz[:, 0]),\n",
    "            \"Y_centroid\": np.mean(xyz[:, 1]),\n",
    "            \"Z_centroid\": np.mean(xyz[:, 2]),\n",
    "            \"m3c2_magnitude_abs_average_per_cluster\": m3c2_mean_distance,\n",
    "            \"volume\": volume,\n",
    "            \"surface_area\": area,\n",
    "            \"surface_to_volume_ratio\": surface_to_volume_ratio,\n",
    "            \"cluster_size_points\": int(cluster_count[cluster_id]),\n",
    "            }\n",
    "        \n",
    "        geometry_ = {\n",
    "            \"type\": \"Polygon\",\n",
    "            # \"coordinates\": XXXX # Use projected coordinates for the polygon\n",
    "            \"coordinates\": [vertices_of_hull[:, :2].tolist()]  # Only use X and Y coordinates for the polygon\n",
    "        }\n",
    "\n",
    "        geoObjects_.append({\n",
    "            \"id\": id_,\n",
    "            \"type\": type_,\n",
    "            \"dateTime\": dateTime_,\n",
    "            \"geometry\": geometry_,\n",
    "            \"customEntityData\": customEntityData_\n",
    "        })\n",
    "        return geoObjects_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba481409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle file download/reading here\n",
    "infolder = r\"D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\"\n",
    "\n",
    "m3c2_settings = {\"cyl_radius\":1,\n",
    "                 \"normal_radii\":[1.0,],\n",
    "                 \"max_distance\": 10.0,\n",
    "                 \"registration_error\":0.025\n",
    "                 }\n",
    "\n",
    "#DBScan parameters\n",
    "dbscan_eps = 1\n",
    "min_cluster_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ee7cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30 14:56:30][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240825_220005.laz'\n",
      "[2025-06-30 14:56:34][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240825_230005.laz'\n",
      "[2025-06-30 14:56:34][INFO] Building KDTree structure with leaf parameter 10\n",
      "[2025-06-30 14:56:34][INFO] Building KDTree structure with leaf parameter 10\n",
      "No clusters found between 240825_220005.laz and 240825_230005.laz.\n",
      "[2025-06-30 14:56:37][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240825_230005.laz'\n",
      "[2025-06-30 14:56:37][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240826_000005.laz'\n",
      "[2025-06-30 14:56:37][INFO] Building KDTree structure with leaf parameter 10\n",
      "[2025-06-30 14:56:37][INFO] Building KDTree structure with leaf parameter 10\n",
      "No clusters found between 240825_230005.laz and 240826_000005.laz.\n",
      "[2025-06-30 14:56:40][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240826_000005.laz'\n",
      "[2025-06-30 14:56:40][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240826_010006.laz'\n",
      "[2025-06-30 14:56:40][INFO] Building KDTree structure with leaf parameter 10\n",
      "[2025-06-30 14:56:40][INFO] Building KDTree structure with leaf parameter 10\n",
      "[2025-06-30 14:56:44][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240826_010006.laz'\n",
      "[2025-06-30 14:56:44][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240826_020005.laz'\n",
      "[2025-06-30 14:56:44][INFO] Building KDTree structure with leaf parameter 10\n",
      "[2025-06-30 14:56:45][INFO] Building KDTree structure with leaf parameter 10\n",
      "No clusters found between 240826_010006.laz and 240826_020005.laz.\n",
      "[2025-06-30 14:56:47][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240826_020005.laz'\n",
      "[2025-06-30 14:56:47][INFO] Reading point cloud from file 'D:\\daten\\projects\\aimon\\low_res_bad_attr_clipped\\240826_030005.laz'\n",
      "[2025-06-30 14:56:47][INFO] Building KDTree structure with leaf parameter 10\n",
      "[2025-06-30 14:56:47][INFO] Building KDTree structure with leaf parameter 10\n",
      "No clusters found between 240826_020005.laz and 240826_030005.laz.\n"
     ]
    }
   ],
   "source": [
    "observations = {\"observations\": []}\n",
    "\n",
    "# Gather & sort only the .laz files\n",
    "laz_files = sorted(f for f in os.listdir(infolder) if f.endswith('.laz'))\n",
    "\n",
    "# Walk through each consecutive pair\n",
    "for prev_fname, curr_fname in zip(laz_files, laz_files[1:]):\n",
    "    prev_path = os.path.join(infolder, prev_fname)\n",
    "    curr_path = os.path.join(infolder, curr_fname)\n",
    "\n",
    "    startDateTime = iso_timestamp(prev_fname)\n",
    "    endDateTime   = iso_timestamp(curr_fname)\n",
    "\n",
    "    # Load point clouds\n",
    "    epoch_0 = py4dgeo.read_from_las(prev_path)\n",
    "    epoch_1 = py4dgeo.read_from_las(curr_path)\n",
    "\n",
    "    # Compute M3C2\n",
    "    m3c2 = py4dgeo.M3C2(\n",
    "        epochs=(epoch_0, epoch_1),\n",
    "        corepoints=epoch_0.cloud,\n",
    "        cyl_radius=m3c2_settings[\"cyl_radius\"],\n",
    "        normal_radii=m3c2_settings[\"normal_radii\"],\n",
    "        max_distance=m3c2_settings[\"max_distance\"],\n",
    "        registration_error=m3c2_settings[\"registration_error\"],\n",
    "    )\n",
    "    distances, uncertainties = m3c2.run()\n",
    "\n",
    "    # Mask & stack only significant changes\n",
    "    mask = np.abs(distances) >= uncertainties[\"lodetection\"]\n",
    "    if not mask.any():\n",
    "        print(f\"No significant changes between {prev_fname} → {curr_fname}\")\n",
    "        continue\n",
    "\n",
    "    significant_pts = epoch_0.cloud[mask]\n",
    "    significant_d  = distances[mask]\n",
    "    changes = np.column_stack((significant_pts, significant_d))\n",
    "\n",
    "    # Cluster & extract geoObjects\n",
    "    labeled = cluster_m3c2_changes(changes, dbscan_eps, min_cluster_size)\n",
    "    geoObjects_ = extract_geoObjects_from_clusters(labeled, endDateTime, prev_fname, curr_fname)\n",
    "\n",
    "    observations[\"observations\"].append({\n",
    "        \"backgroundImageData\": {},\n",
    "        \"startDateTime\": startDateTime,\n",
    "        \"endDateTime\": endDateTime,\n",
    "        \"geoObjects\": geoObjects_,\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
